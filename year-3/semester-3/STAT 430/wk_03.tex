\makeheading{Week 3}
\section{Permutation and Randomization Tests}
\begin{itemize}
      \item All the previous tests have made some kind of distributional assumption
            for the response measurements, such as $ Y_{ij} \sim \N{\mu_j,\sigma^2} $ or
            $ Y_{ij}\sim \bin{1,\pi_j} $.
      \item It would be preferable to have a test that does not rely on \emph{any}
            assumptions.
      \item This is precisely the purpose of permutation and randomization tests.
            \begin{itemize}
                  \item These tests are \emph{non-parametric} and rely on sampling.
                  \item The motivation is that if $ H_0 $: $ \theta_1=\theta_2 $
                        is true, any random rearrangement of the data is \emph{equally likely
                              to have been observed}. If $ H_0 $ is true, then we have a single population
                        from which our data has been drawn.
                  \item With $ n_1 $ and $ n_2 $ units in each condition, there are
                        \[ \binom{n_1+n_2}{n_1}=\binom{n_1+n_2}{n_2} \]
                        arrangements of the $ n_1+n_2 $ observations into two groups of size $ n_1 $
                        and $ n_2 $ respectively.
                        \[ n_1=n_2=50\implies\binom{n_1+n_2}{n_1}=\binom{100}{50}=1.0089\times 10^{29} \]
            \end{itemize}
      \item A true \textbf{permutation test} considers \emph{all possible rearrangements}
            of the original data.
            \begin{itemize}
                  \item The test statistic $ t $ is calculated on the original data and on every one of
                        its rearrangements.
                  \item This collection of test statistic values generate the empirical null distribution.
            \end{itemize}
      \item A \textbf{randomization test} is carried out similarly, except that we do not
            consider all possible rearrangements.
            \begin{itemize}
                  \item We just consider a large number $ N $ of them.
            \end{itemize}
\end{itemize}
\begin{framed}
      \textbf{Randomization Test Algorithm}
      \begin{enumerate}
            \item Collect response observations in each condition.
                  \[ \set{y_{11},y_{21},\ldots,y_{n_1 1}}\to \hat{\theta}_1 \]
                  \[ \set{y_{12},y_{22},\ldots,y_{n_2 2}}\to \hat{\theta}_2 \]
            \item Calculate the test statistic $ t $ on the original data.
                  \[ t=\hat{\theta}_1-\hat{\theta}_2\quad\text{or}\quad t=\frac{\hat{\theta}_1}{\hat{\theta}_2} \]
            \item Pool all the observations together and randomly sample (without replacement)
                  $ n_1 $ observations which will be assigned to ``Condition 1'' and the remaining $ n_2 $
                  observations that are assigned to ``Condition 2.''
                  \[ \set{y_{11}^\star,y_{21}^\star,\ldots,y_{n_1 1}^\star}\to \hat{\theta}_1^\star \]
                  \[ \set{y_{12}^\star,y_{22}^\star,\ldots,y_{n_2 2}^\star}\to \hat{\theta}_2^\star \]
            \item Calculate the test statistic $ t_k^\star $ on each of the ``shuffled'' datasets, $ k=1,2,\ldots,N $.
                  \[ t_k^\star=\hat{\theta}_{1,k}^\star-\hat{\theta}_{2,k}^\star\quad\text{or}\quad t_k^\star=\frac{\hat{\theta}_{1,k}^\star}{\hat{\theta}_{2,k}^\star}  \]
            \item Compare to $ t $ to $ \set*{t_1^\star,t_2^\star,\ldots,t_N^\star} $, the empirical
                  null distribution, and calculate the $ p $-value:
                  \[ p\text{-value}=\frac{\text{\# of $t$'s that are at least as extreme as $t$}}{N}  \]
                  \begin{itemize}
                        \item $ H_0 $: $ \theta_1=\theta_2 $ versus $ H_\text{A} $: $ \theta_1\ne \theta_2 $. If $ t=\hat{\theta}_1-\hat{\theta}_2 $, then
                              the $ p $-value is:
                              \[ p\text{-value}=\frac{1}{N} \sum_{k=1}^{N} \Ind*{t_k^\star\ge \abs{t}\cup t_k^\star\le -\abs{t}} \]
                        \item $ H_0 $: $ \theta_1\ge \theta_2 $ versus $ H_\text{A} $: $ \theta_1<\theta_2 $. If $ t=\hat{\theta}_1-\hat{\theta}_2 $, then
                              the $ p $-value is:
                              \[ p\text{-value}=\frac{1}{N} \sum_{k=1}^{N} \Ind*{t_k^\star\le t} \]
                        \item $ H_0 $: $ \theta_1\le \theta_2 $ versus $ H_\text{A} $: $ \theta_1>\theta_2 $. If $ t=\hat{\theta}_1-\hat{\theta}_2 $, then
                              the $ p $-value is:
                              \[ p\text{-value}=\frac{1}{N} \sum_{k=1}^{N} \Ind*{t_k^\star\ge t} \]
                  \end{itemize}
      \end{enumerate}
\end{framed}
\begin{Example}{Pokémon Go}{}
      \begin{itemize}
            \item Suppose that Niantic Inc, is experimenting with two different promotions within Pokémon
                  Go:
                  \begin{itemize}
                        \item Condition 1: Give users nothing.
                        \item Condition 2: Give users 200 free Pokécoins.
                        \item Condition 3: Give users a 50\% discount on Shop purchases.
                  \end{itemize}
            \item In a small pilot experiment $ n_1=n_2=n_3=100 $ users are randomized to each condition.
            \item For each user, the amount of real money (in USD) they spend in the 30 days following
                  the experiment is recorded.
            \item The data summaries are:
                  \begin{itemize}
                        \item $ \bar{y}_1=\$10.74 $, $ Q_{y_1}(0.5)=\$9 $.
                        \item $ \bar{y}_2=\$9.53 $, $ Q_{y_2}(0.5)=\$8 $.
                        \item $ \bar{y}_3=\$13.41 $, $ Q_{y_3}(0.5)=\$10 $.
                  \end{itemize}
                  Using R, we performed a randomization test with $ N=10\,000 $ with respect to the mean
                  we found that the control and free coin conditions did not significantly differ.
                  But there was a significant increase in the amount of money spend in the discount condition
                  relative to the other two.

                  \vspace{2mm}

                  The hypotheses that we tested to determine these conclusions were:

                  \centerline{$ H_0 $: $ \mu_1=\mu_2 $ versus $ H_\text{A} $: $ \mu_1\ne \mu_2 $}
                  \centerline{$ H_0 $: $ \mu_1\ge \mu_2 $ versus $ H_\text{A} $: $ \mu_1<\mu_2 $}

                  Interestingly, when you run these same tests, but on the basis of the median, we find
                  no significant difference between any of the conditions.
            \item \href{https://github.com/Hextical/university-notes/blob/master/year-3/semester-3/STAT 430/code/Randomization_test.R}{[R Code] \texttt{Randomization\_test}}
      \end{itemize}
\end{Example}
\chapter{Experiments with More than Two Conditions}
\section*{Anatomy of an ``A/B/m'' Test}
\begin{itemize}
      \item One design factor at $ m $ levels.
      \item We will now consider a design and analysis of an experiment consisting
            of more than two experimental conditions --- or what many data scientists
            broadly refer to as ``A/B/$m$ Testing.''
            \begin{itemize}
                  \item Canonical A/B/$ m $ test: What colour maximizes click-through rate?
            \end{itemize}
      \item Other, more tangible, examples:
            \begin{itemize}
                  \item Netflix.
                  \item Etsy.
            \end{itemize}
      \item Typically, the goal of such an experiment is to decide which condition is
            optimal with respect to some metric of interest $ \theta $. This could be a:
            \begin{itemize}
                  \item mean
                  \item proportion
                  \item variance
                  \item quantile
                  \item technically any statistic that can be calculated from sample data
            \end{itemize}
      \item From a design standpoint, such an experiment is \emph{very} similar to
            a two-condition experiment.
            \begin{enumerate}
                  \item Choose a metric of interest $ \theta $ which addresses the question
                        you are trying to answer.
                  \item Determine the response variable $ y $ that must be measured on each
                        unit to estimate $ \hat{\theta} $.
                  \item Choose the design factor $ x $ and the $ m $ levels you will experiment with.
                  \item Choose $ n_1,n_2,\ldots,n_m $ and assign units to conditions at random.
                  \item Collect the data and estimate the metric of interest in each condition:
                        \[ \hat{\theta}_1,\hat{\theta}_2,\ldots,\hat{\theta}_m \]
            \end{enumerate}
      \item Determining which conditional is optimal typically involves a series of pairwise
            comparisons: $ t $-tests or $ z $-tests.
      \item But it is useful to begin such an investigation with a \emph{gatekeeper}
            test (overall equality) which serves to determine whether
            there is \emph{any} difference between the $ m $ experimental conditions.
            Formally, such a question is phrased as the following statistical hypothesis:

            \centerline{$ H_0 $: $ \theta_1=\theta_2=\cdots=\theta_m $ versus $ H_\text{A} $: $ \theta_j\ne \theta_k $ for some $ j\ne k $}

            In the case of means:

            \centerline{$ H_0 $: $ \mu_1=\mu_2=\cdots=\mu_m $ versus $ H_\text{A} $: $ \mu_j\ne \mu_k $ for some $ j\ne k $}

            In the case of proportions:

            \centerline{$ H_0 $: $ \pi_1=\pi_2=\cdots=\pi_m $ versus $ H_\text{A} $: $ \pi_j\ne \pi_k $ for some $ j\ne k $}
\end{itemize}
\section{Comparing Means in Multiple Conditions}
\begin{itemize}
      \item We assume that our response variable follows a normal distribution,
            and we assume that the mean of the distribution depends on the condition
            in which the measurements were taken, and that the variance
            is the same across all conditions.
            \[ Y_{ij}\sim \N{\mu_j,\sigma^2}\quad\text{for }i=1,2,\ldots,n_j\text{ and }j=1,2 \]
      \item The ``gatekeeper'' test for means is tested using an $ F $-test:

            \centerline{$ H_0 $: $ \mu_1=\mu_2=\cdots=\mu_m $}
\end{itemize}
\subsection{The \texorpdfstring{$ F $}{F}-test for Overall Significance in a Linear Regression}
\begin{itemize}
      \item In particular, we use the $ F $-test for overall significance in an
            \emph{approximately defined linear regression model}:
            \begin{itemize}
                  \item The appropriately defined linear regression model
                        in this situation is one in which the response
                        variable depends on $ m-1 $ indicator variables:
                        \[ x_{ij}=\begin{cases*}
                                    1 & if unit $ i $ is in condition $ j $ \\
                                    0 & otherwise
                              \end{cases*}\quad\text{for}j=1,2,\ldots,m-1. \]
                  \item For a particular unit $ i $, we adopt the model:
                        \[ Y_{i}=\beta_0+\beta_1x_{i1}+\beta_2x_{i2}+\cdots+\beta_{m-1}x_{i,m-1}+\varepsilon_i \]
                        \begin{itemize}
                              \item $ Y_i = $ response observation for unit $ i=1,2,\ldots,N=\sum_{j=1}^{m} n_j $.
                              \item $ \varepsilon_i = $ random error term which we assume follows a $ \N{0,\sigma^2} $ distribution.
                              \item Because we're about to do a regression analysis, the usual \emph{residual diagnostics} are relevant.
                        \end{itemize}
                  \item In this model the $ \beta $'s are unknown parameters
                        and may be interpreted in the context of the
                        following expectations:
                        \begin{itemize}
                              \item Expected response in condition $ m $:
                                    \[ \E{Y_i\given x_{i1}=x_{i2}=\cdots=x_{i,m-1}=0}=\beta_0=\mu_m \]
                              \item Expected response in condition $ j $:
                                    \[ \E{Y_i\given x_{ij}=1}=\beta_0+\beta_j=\mu_j\quad\text{for }j=1,2,\ldots,m-1 \]
                        \end{itemize}
                        \begin{itemize}
                              \item $ \beta_j $ is interpreted as the expected difference in response value
                                    in condition $ j $ versus condition $ m $.
                                    \begin{align*}
                                          \mu_1     & =\beta_0+\beta_1      \\
                                          \mu_2     & =\beta_0+\beta_2      \\
                                                    & \vdotswithin{=}       \\
                                          \mu_{m-1} & = \beta_0+\beta_{m-1} \\
                                          \mu_m     & =\beta_0
                                    \end{align*}
                        \end{itemize}
                  \item Based on these assumptions $ H_0 $: $ \theta_1=\theta_2=\cdots=\theta_m $
                        is true if and only if $ \beta_1=\beta_2=\cdots=\beta_{m-1}=0 $, and hence is equivalent
                        to testing:

                        \centerline{$ H_0 $: $ \beta_1=\beta_2=\cdots=\beta_{m-1} $ versus $ H_\text{A} $: $ \beta_j\ne 0 $ for some $ j$}
                  \item This hypothesis corresponds, as noted, to the $ F $-test for overall significance in the model.
            \end{itemize}
      \item  In regression parlance, the test statistic is defined to be the ratio of the
            regression mean squares (MSR)
            to the mean squared error (MSE) in a standard regression-based analysis of variance (ANOVA):
            \[ t=\frac{\text{MSR}}{\text{MSE}} \]
      \item In our setting we can more intuitively think of the test
            statistic as comparing the response variability
            between conditions to the response variability within conditions:
            \begin{itemize}
                  \item Average response in condition $ j $: $ \displaystyle \bar{y}_{\bullet j}=\frac{1}{n_j} \sum_{i=1}^{n_j} y_{ij} $.
                  \item Overall average response: $ \displaystyle \bar{y}_{\bullet\bullet}=\frac{1}{N} \sum_{j=1}^{m} \sum_{i=1}^{n_j} y_{ij}=\frac{1}{N} \sum_{j=1}^{m} n_j\bar{y}_{\bullet j} $.
                  \item Quantifies variability \underline{\emph{between}} conditions:
                        $ \displaystyle \text{SS}_\text{C}=\sum_{j=1}^{m} \sum_{i=1}^{n_j} \bigl(\bar{y}_{\bullet j}-\bar{y}_{\bullet\bullet}\bigr)^2 $.
                  \item Quantifies variability \underline{\emph{within}} conditions:
                        $ \displaystyle \text{SS}_\text{E}=\sum_{j=1}^{m} \sum_{i=1}^{n_j} \bigl(y_{ij}-\bar{y}_{\bullet j}\bigr)^2 $.
                  \item Quantifies \underline{\emph{overall}} variability:
                        $ \displaystyle \text{SS}_\text{T}=\sum_{j=1}^{m} \sum_{i=1}^{n_j} \bigl(y_{ij}-\bar{y}_{\bullet\bullet}\bigr)^2=\text{SS}_\text{C}+\text{SS}_\text{E} $.
            \end{itemize}
      \item The null distribution for this test is $ F(m-1,N-m) $.
      \item The $ p $-value for this test is calculated by
            $ p\text{-value}=\Prob{T\ge t} $ where $ T \sim F(m-1,N-m) $.
\end{itemize}
\begin{table}[!htbp]
      \centering
      \caption{ANOVA Table}\vspace{1mm}
      \begin{tabularx}{0.85\linewidth}{@{}YYYYY@{}}
            \toprule
            Source    & SS                     & d.f.    & MS                           & Test Stat.                                                   \\
            \midrule
            Condition & $ \text{SS}_\text{C} $ & $ m-1 $ & $ \text{SS}_\text{C}/(m-1) $ & \multirow{2}{*}{$ t=\text{MS}_\text{C}/\text{MS}_\text{E} $} \\
            Error     & $ \text{SS}_\text{E} $ & $ N-m $ & $ \text{SS}_\text{E}/(N-m) $                                                                \\
            \midrule
            Total     & $ \text{SS}_\text{T} $ & $ N-1 $                                                                                               \\
      \end{tabularx}
\end{table}
\subsection{Example: Candy Crush Boosters}
\begin{Example}{Candy Crush Boosters}{}
      \begin{itemize}
            \item Candy Crush is experimenting with three different versions of
                  in-game ``boosters'': the lollipop hammer, the jelly fish, and the colour bomb.
            \item Users are randomized to one of these three conditions ($ n_1 = 121 $,
                  $ n_2 = 135 $, $ n_3 = 117$) and they
                  receive (for free) 5
                  boosters corresponding to their condition.
                  Interest lies in evaluating the effect
                  of these different boosters on the length of time a user plays the game.
            \item Let $ \mu_j $ represent the average length of game play
                  (in minutes) associated with booster condition
                  $ j = 1, 2, 3 $. While interest lies in finding the condition
                  associated with the longest average length
                  of game play, here we first rule out the possibility
                  that booster type does not influence the length
                  of game play (i.e., $ \mu_1=\mu_2=\mu_3 $).
            \item In order to do this we fit the linear regression model:
                  \[ Y=\beta_0+\beta_1 x_1+\beta_2 x_2+\varepsilon \]
                  where the $ x $'s are indicator variables indicating whether a particular value
                  of the response was observed in the jelly fish or colour bomb conditions.
                  The lollipop hammer is therefore the reference condition.
            \item In R, we found that the test statistic for testing:

                  \centerline{$ H_0 $: $ \mu_1=\mu_2=\mu_3 $ versus $ H_\text{A} $: $ \mu_j\ne \mu_k $
                        for some $ j\ne k $}
                  was $ t=851.8947 $ and the null distribution was $ T \sim F(2,370) $. The corresponding
                  $ p $-value was:
                  \[ p\text{-value}=\Prob{T\ge 851.8947}=3.28\times 10^{-139} \]
            \item Therefore, we have very strong evidence against $ H_0 $ and conclude that the average
                  length of game play is not the same in the three booster conditions.
            \item \href{https://github.com/Hextical/university-notes/blob/master/year-3/semester-3/STAT 430/code/Comparing_multiple_means.R}{[R Code] \texttt{Comparing\_multiple\_means}}
      \end{itemize}
\end{Example}
\section{Comparing Proportions in Multiple Conditions}
\begin{itemize}
      \item As is always the case when comparing proportions is of interest, we assume that our response variable
            is binary:
            \[ Y_{ij}=\begin{cases*}
                        1 & if unit $ i $ in condition $ j $ performs an action of interest         \\
                        0 & if unit $ i $ in condition $ j $ deos not perform an action of interest
                  \end{cases*}i=1,2,\ldots,n_j;j=1,2,\ldots,m \]
            \[ Y_{ij}\sim \bin{1,\pi_j} \]
            where $ \pi_j $ is the probability of a unit in condition $ j $ performing the action.
      \item The ``gatekeeper'' test for proportions is tested using the \textbf{chi-squared test
                  of independence} (also known as Pearson $ \chi^2 $-test).

            \centerline{$ H_0 $: $ \pi_1=\pi_2=\cdots=\pi_m $}
\end{itemize}
\subsection{The Chi-squared Test of Independence}
\begin{itemize}
      \item The chi-squared test of independence is typically used as a test for `no association'
            between two categorical variables that are summarized in a \emph{contingency table}.
      \item We apply this methodology here to test the independence of the binary outcome
            (whether a unit performs the action of interest) and the particular condition they are in.
      \item To start, let's assume that $ m=2 $, and let's use the \hyperref[ex:optimizely_ex1]{Optimizely experiment}.
            \begin{itemize}
                  \item If $ \pi_1=\pi_2=\pi $, then we would expect the conversion rate in each condition to be the same.
                  \item An estimate of the pooled conversion rate in this case is $ \hat{\pi}=679/17514=0.0388 $.
                  \item Let $ X= $ number of conversions in a condition with $ n $ units, therefore $ X \sim \bin{n,\pi} $
                        where $ \E{X}=n\pi $.
                  \item Therefore, we would expect $ n_1\hat{\pi}=8872(0.0388)=343.96 $ conversions in condition 1,
                        and $ n_2\hat{\pi}=8642(0.0388)=335.04 $ conversions in condition 2.
                  \item The chi-squared test formally evaluates if the difference between what
                        was observed and what is expected under the null hypothesis is large enough
                        to be considered \emph{significantly} different.
                  \item The \emph{general} $ 2\times 2 $ contingency table for a scenario like this
                        is shown below.
                        \begin{table}[!htbp]
                              \centering
                              \begin{tabularx}{0.8\linewidth}{@{}BYYYY@{}}
                                    \multicolumn{2}{c}{}        & \multicolumn{2}{c}{\textbf{Condition}} &                                                                                       \\
                                    \multicolumn{2}{c}{}        & 1                                      & 2                         & \multicolumn{1}{c}{}                                      \\
                                    \cmidrule{2-5}
                                    \multirow{2}{*}{Conversion} & Yes                                    & $O_{1,1}$                 & $O_{1,2}$                 & $O_1$                         \\
                                                                & No                                     & $O_{0,1}$                 & $O_{0,2}$                 & $O_2$                         \\
                                    \cmidrule{2-5}
                                    \multicolumn{1}{c}{}        & \multicolumn{1}{c}{}                   & \multicolumn{1}{c}{$n_1$} & \multicolumn{1}{c}{$n_2$} & \multicolumn{1}{c}{$n_1+n_2$} \\
                              \end{tabularx}
                        \end{table}
                        \begin{itemize}
                              \item $ O_{\ell,j} = $ the observed number of conversions ($ \ell=1 $),
                                    and the observed number of non-conversions ($ \ell=0 $) in condition $ j=1,2 $.
                              \item $ O_\ell= $ overall number of conversions ($ \ell=1 $) or non-conversions
                                    ($ \ell=0 $)
                        \end{itemize}
                  \item So,
                        \[ \hat{\pi}=\frac{O_1}{n_1+n_2}\quad \text{ and }\quad 1-\hat{\pi}=\frac{O_0}{n_1+n_2} \]
                        represent the overall proportions of units that did or did not convert, they
                        are estimates of overall conversion and non-conversion rates.
                  \item Let $ E_{1,j} $ and $ E_{0,j} $
                        represent the expected number of conversions and non-conversions in condition
                        $ j=1,2 $,
                        \[ E_{1,j}=n_j\hat{\pi}\quad \text{ and }\quad E_{0,j}=n_j(1-\hat{\pi}) \]
                        \begin{itemize}
                              \item This is what we expect if $ H_0 $: $ \pi_1=\pi_2 $ is true.
                        \end{itemize}
                  \item The $ \chi^2 $ test statistic compares the observed count
                        in each cell to the corresponding expected
                        count, and is defined as
                        \[ T=\sum_{\ell=0}^{1} \sum_{j=1}^{2} \frac{(O_{\ell_j}-E_{\ell,j})^2}{E_{\ell,j}}\sim \chi^2(1)  \]
                  \item The $ p $-value for this test is calculated by $ p\text{-value} = \Prob{T\ge t} $ where
                        $ T \sim \chi^2(1) $.
                  \item Returning to the Optimizely example, the \emph{expected} table is:
                        \begin{table}[!htbp]
                              \centering
                              \begin{tabularx}{0.8\linewidth}{@{}BYYYY@{}}
                                    \multicolumn{2}{c}{}        & \multicolumn{2}{c}{\textbf{Condition}} &                                                                                       \\
                                    \multicolumn{2}{c}{}        & 1                                      & 2                          & \multicolumn{1}{c}{}                                     \\
                                    \cmidrule{2-5}
                                    \multirow{2}{*}{Conversion} & Yes                                    & $343.96$                   & $335.04$                   & $679$                       \\
                                                                & No                                     & $8528.04$                  & $8306.96$                  & $16835$                     \\
                                    \cmidrule{2-5}
                                    \multicolumn{1}{c}{}        & \multicolumn{1}{c}{}                   & \multicolumn{1}{c}{$8872$} & \multicolumn{1}{c}{$8642$} & \multicolumn{1}{c}{$17514$} \\
                              \end{tabularx}
                        \end{table}
                  \item And the resultant test statistic and $p$-value are:
                        \[ t=\frac{(280-343.96)^2}{343.96} +\frac{(399-335.04)^2}{335.04}+\frac{(8592-8528.04)^2}{8528.04}+\frac{(8243-8306.96)^2}{8306.96}=25.075    \]
                        \[ p\text{-value}=\Prob{T\ge 25.075}=5.52\times 10^{-7} \]
            \end{itemize}
      \item Let's now extend this for $ m>2 $.
            \begin{itemize}
                  \item We've used the chi-squared test is a test of `no association' between the binary outcome (whether
                        a unit performs the action of interest) and the particular condition they are in.
                        \begin{itemize}
                              \item But there is no requirement that there be only two conditions.
                              \item Here we generalize the test to any number of experimental conditions.
                        \end{itemize}
                  \item The information associated with this test can be summarized in a $ 2\times m $ contingency table:
                        \begin{table}[!htbp]
                              \centering
                              \begin{tabularx}{\linewidth}{@{}BYYYYYY@{}}
                                    \multicolumn{2}{c}{}        & \multicolumn{4}{c}{\textbf{Condition}} &                                                                                                                                           \\
                                    \multicolumn{2}{c}{}        & 1                                      & 2                         & $\cdots$                  & $m$      & \multicolumn{1}{c}{}                                                   \\
                                    \cmidrule{2-7}
                                    \multirow{2}{*}{Conversion} & Yes                                    & $O_{1,1}$                 & $O_{1,2}$                 & $\cdots$ & $O_{1,m}$                 & $O_1$                                      \\
                                                                & No                                     & $O_{0,1}$                 & $O_{0,2}$                 & $\cdots$ & $O_{0,m}$                 & $O_2$                                      \\
                                    \cmidrule{2-7}
                                    \multicolumn{1}{c}{}        & \multicolumn{1}{c}{}                   & \multicolumn{1}{c}{$n_1$} & \multicolumn{1}{c}{$n_2$} & $\cdots$ & \multicolumn{1}{c}{$n_m$} & \multicolumn{1}{c}{$N=\sum_{j=1}^{m} n_j$} \\
                              \end{tabularx}
                        \end{table}
                        \begin{itemize}
                              \item \# of conversions ($ \ell=1 $) or non-conversions ($ \ell=0 $) is condition
                                    $ j=1,2 $.
                              \item $ \hat{\pi}=O_1/N $.
                              \item $ 1-\hat{\pi}=O_0/N $.
                        \end{itemize}
                  \item We contract each of the observed frequencies $ O_{1,j} $ with the corresponding expected
                        frequency $ E_{\ell,j} $.
                        \[ E_{1,j}=n_j\hat{\pi}\quad\text{and}\quad E_{0,j}=n_j(1-\hat{\pi}) \]
                        \begin{itemize}
                              \item Expected number of conversions/non-conversions in condition $ j $
                                    assuming $ H_0 $: $ \pi_1=\pi_2=\cdots=\pi_m $ is true.
                        \end{itemize}
                  \item The $ \chi^2 $ test statistic
                        compares the observed count in each cell to the corresponding expected
                        count, and is defined as:
                        \[ T=\sum_{\ell=0}^{1} \sum_{j=1}^{m} \frac{(O_{\ell,j}-E_{\ell,j})^2}{E_{\ell_j}}\sim \chi^2(m-1)  \]
                  \item The $ p $-value associated with this test is calculated as
                        $ p\text{-value} = \Prob{T\ge t} $ where $ T \sim \chi^2(m-1) $.
            \end{itemize}
\end{itemize}
\begin{Example}{Nike SB Ads}{}
      \begin{itemize}
            \item Suppose that Nike is running an ad campaign for Nike SB, their
                  skateboarding division, and the
                  campaign involves $ m = 5 $ different
                  video ads that are being shown in Facebook newsfeeds.
            \item A video ad is `viewed' if it is watched for longer than 3 seconds,
                  and interest lies in determining
                  which ad is most popular and hence most profitable
                  by comparing the viewing rates of the five
                  different videos.
            \item Each of these 5 videos is shown to $ n_1=5014 $, $ n_2=4971 $, $ n_3=5030 $,
                  $ n_4=5007 $, and $ n_5=4980 $ users, and the results are summarized in the table below.
                  \begin{center}
                        \begin{tabularx}{\linewidth}{@{}BYYYYYYY@{}}
                              \multicolumn{2}{c}{}  & \multicolumn{5}{c}{\textbf{Condition}} &                                                                                                                                                                              \\
                              \multicolumn{2}{c}{}  & 1                                      & 2                          & 3                          & 4                          & 5                          & \multicolumn{1}{c}{}                                     \\
                              \cmidrule{2-8}
                              \multirow{2}{*}{View} & Yes                                    & $160$                      & $95$                       & $141$                      & $293$                      & $197$                      & $886$                       \\
                                                    & No                                     & $4854$                     & $4876$                     & $4889$                     & $4714$                     & $4783$                     & $24116$                     \\
                              \cmidrule{2-8}
                              \multicolumn{1}{c}{}  & \multicolumn{1}{c}{}                   & \multicolumn{1}{c}{$5014$} & \multicolumn{1}{c}{$4971$} & \multicolumn{1}{c}{$5030$} & \multicolumn{1}{c}{$5007$} & \multicolumn{1}{c}{$4980$} & \multicolumn{1}{c}{$25002$} \\
                        \end{tabularx}
                  \end{center}
            \item The overall watch rate (and its complement) are:
                  \[ \hat{\pi}=\frac{O_1}{N} =\frac{886}{25002}=0.0354\quad\text{and}\quad 1-\hat{\pi}=\frac{24116}{25002} =0.9649 \]
            \item The expected cell frequencies are found by multiplying $ n_j $ by $ \hat{\pi} $
                  and $ (1-\hat{\pi}) $ for $ j=1,2,3,4,5 $.
                  \begin{center}
                        \begin{tabularx}{\linewidth}{@{}BYYYYYYY@{}}
                              \multicolumn{2}{c}{}  & \multicolumn{5}{c}{\textbf{Condition}} &                                                                                                                                                                              \\
                              \multicolumn{2}{c}{}  & 1                                      & 2                          & 3                          & 4                          & 5                          & \multicolumn{1}{c}{}                                     \\
                              \cmidrule{2-8}
                              \multirow{2}{*}{View} & Yes                                    & $177.68$                   & $176.16$                   & $178.25$                   & $177.43$                   & $176.48$                   & $886$                       \\
                                                    & No                                     & $4836.32$                  & $4794.84$                  & $4851.75$                  & $4829.57$                  & $4803.52$                  & $24116$                     \\
                              \cmidrule{2-8}
                              \multicolumn{1}{c}{}  & \multicolumn{1}{c}{}                   & \multicolumn{1}{c}{$5014$} & \multicolumn{1}{c}{$4971$} & \multicolumn{1}{c}{$5030$} & \multicolumn{1}{c}{$5007$} & \multicolumn{1}{c}{$4980$} & \multicolumn{1}{c}{$25002$} \\
                        \end{tabularx}
                  \end{center}
            \item The resultant test statistic and $ p $-value (where $ T \sim \chi^2(4) $) are:
                  \[ t=\sum_{\ell=0}^{1} \sum_{j=1}^{m} \frac{(O_{\ell,j}-E_{\ell,j})^2}{E_{\ell,j}} =129.1686 \]
                  \[ p\text{-value}=\Prob{T\ge 129.1686}=5.86\times 10^{-27} \]
            \item Therefore, we reject $ H_0 $: $ \pi_1=\pi_2=\cdots=\pi_5 $ and conclude that
                  the ``watch-rate'' is not the same for each of the video ads.
            \item \href{https://github.com/Hextical/university-notes/blob/master/year-3/semester-3/STAT 430/code/Comparing_multiple_proportions.R}{[R Code] \texttt{Comparing\_multiple\_proportions}}
      \end{itemize}
\end{Example}
