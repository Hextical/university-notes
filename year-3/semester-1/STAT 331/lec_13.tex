\makeheading{Lecture 13 | 2020-10-26}
Model selection:
Given $ p $ explanatory variables, find the subset
$ k\leqslant p $ of explanatory variables
(``reduced model'') that gives us
the ``best'' model: goodness of fit,
interpretability, predictive performance.

Some related concepts:
\begin{enumerate}
    \item $ F $ tests compare between $ 2 $
          specific models where test adequacy of
          a ``reduced'' model (subset, ``nested'')
          relative to full model.

          \underline{Quiz 4}: $ \beta_1=\beta_2 $
    \item Multicollinearity: can affect interpretability
          of $ \hat{\beta}_j $ usual interpretation
          ``holding other variables constant''
          doesn't really work when $ x_j $ is
          strongly correlated with other predictors.
    \item $ R^2 $ is the proportion
          of variability in the response explained by
          the regression model. It always increases
          when adding variables.
    \item $ \hat{\sigma}^2 $ is estimated residual variable,
          used for prediction, want $ \hat{\sigma}^2 $ small
\end{enumerate}
Two key ingredients:
\begin{itemize}
    \item Metric (or criterion) for comparing
          different models with potentially different number
          of predictors
\end{itemize}
