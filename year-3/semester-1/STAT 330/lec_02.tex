\makeheading{Lecture 2 | 2020-09-09}
\section{Discrete Random Variables}
\begin{Definition}{Discrete random variable}{}
    If a random variable $ X $ can only take
    finite or countable values, $ X $
    is a \textbf{discrete random variable}.
\end{Definition}
\begin{Remark}{}{}
    When we say \textbf{countable}, we mean
    something you can enumerate such as $ \mathbf{Z} $ or
    $ \mathbf{N}^+ $.
\end{Remark}

\begin{Definition}{Probability function}{}
    If $ X $ is a discrete random variable,
    then the \textbf{probability function} (p.f.) of $ X $ is given by
    \[ f(x)=
        \begin{dcases}
            \Prob{X=x} & \text{ if } X\text{ can take value }x    \\
            0          & \text{ if } X\text{ cannot take value }x
        \end{dcases} \]
\end{Definition}

\begin{Definition}{Support}{}
    The set $ A=\set{x:f(x)>0} $ is called the \textbf{support}
    of $ X $. These are all the possible values $ X $ can take.
\end{Definition}

\begin{Proposition}{Properties of the Probability Function}{ds_prob_prop}
    \begin{enumerate}[label=(\arabic*)]
        \item $ f(x)\ge 0 $ for all $ x\in\mathbf{R} $
        \item $ \sum\limits_{x\in A}f(x)=1 $
    \end{enumerate}
\end{Proposition}

Review some commonly used discrete random variables:
\begin{itemize}
    \item \textbf{Bernoulli.} $ X \sim \bern{p} $
          where $ X $ can only take two possible values 0 (failure) or 1 (success).
          Let $ p $ be the probability of a success for a single trial. So,
          \[ \Prob{X=1}=p\quad\text{ and }\quad \Prob{X=0}=1-p \]
          \begin{Example}{Bernoulli}{}
              Toss a coin twice. Let $ X $ be the number of heads.
              Therefore, $ X \sim \bern{p} $.
          \end{Example}
    \item \textbf{Binomial.} $ X \sim \bin{n,p} $. Suppose
          we have \textbf{Bernoulli Trials}:
          \begin{itemize}
              \item We run $ n $ trials
              \item Each trial is independent of each other
              \item Each trial has two possible outcomes: 0 (failure), 1 (success)
          \end{itemize}
          \[ \Prob{X=1}=p \]
          Let $ X $ be the number of success across these $ n $ trials
          and $ p $ be the success probability for a single trial.
          \[ X=\sum\limits_{i=1}^{n} X_i \]
          $ X_i $ is the outcome of the $ i^{\text{th}} $ trial.
          \[ \Prob{X_i=1}=p \]
          where $ X_i \sim \bern{p} $.
    \item \textbf{Geometric.} $ X \sim \geo{p} $.
          Let $ X $ be the number of failures before the first success.
          \begin{Example}{Geometric}{}
              $ X = $ number of tails before you get the first
              head. Therefore, $ X \sim \geo{p} $.
          \end{Example}
          $ X $ can take values $ 0,1,2,\ldots $.
          \[ \Prob{X=x}=(1-p)^x p \]
    \item \textbf{Negative Binomial.} $ X \sim \nb{r,p} $.
          Let $ X $ be the number of failures before you get $ r $ success.
          $ X $ can take values $ 0,1,2,\ldots $
          \[ f(x)=\Prob{X=x}=\binom{x+r-1}{x}(1-p)^x p^{r-1}p \]
          \begin{Example}{Negative Binomial}{}
              $ X= $ number of tails before you get the $ r^{\text{th}} $ head.
              Therefore, $ X \sim \nb{r,p} $.
          \end{Example}
    \item \textbf{Poisson.} $ X \sim \poi{\mu} $
          \[ f(x)=\Prob{X=x}=\frac{\mu^x}{x!} e^{-\mu} \]
          where $ 0\le x\in\mathbf{Z} $.
\end{itemize}

\section{Continuous Random Variables}
\begin{Definition}{Continuous random variable}{}
    If the possible values of $ X $ is an interval or real line,
    $ X $ is a \textbf{continuous random variable}. In this case,
    $ F(x) $ is continuous and differentiable
    almost everywhere. (It's not differentiable for at
    most a countable set of points).
\end{Definition}
Note that this is not a rigorous definition, but it will be
used in this course.

\begin{Definition}{Probability density function, Support}{}
    The \textbf{probability density function} (p.d.f.) of a continuous random variable
    is
    \[ f(x)=\begin{cases}
            F^\prime(x) & \text{if }F(x)\text{ is differentiable at }x \\
            0           & \text{otherwise}
        \end{cases} \]
    The set $ A=\set{x:f(x)>0} $ is called the \textbf{support}
    of $ X $.
\end{Definition}

Continuous case: $ f(x)\neq \Prob{X=x} $
\[ \Prob{x<X\le x+\delta}\approx f(x)\delta \]
since
\[ \lim\limits_{{\delta} \to {0}}\frac{F(x+\delta)-F(x)}{\delta}=F^\prime(x)=f(x) \]
where $ F(x+\delta)-F(x)=\Prob{x\le X\le x+\delta} $.
\begin{Definition}{Properties --- Probability Density Function}{}
    \begin{enumerate}[label=(\Roman*)]
        \item $ f(x)\ge 0 $ for all $ x\in\mathbf{R} $
        \item $ \displaystyle \int_{-\infty}^{\infty} f(x)\, d{x}= 1 $
        \item $ \displaystyle F(x)=\int_{-\infty}^{x} f(t)\, d{t} $
              with $ F(-\infty)=0 $
        \item $ f(x)=F^\prime(x) $
        \item $ \Prob{X=x}=0\ne f(x) $
        \item $ \displaystyle
                  \Prob{a<X\le b}=\Prob{a\le X\le b}=\Prob{a<X<b}=\Prob{a\le X <b}=
                  F(b)-F(a)=\int_{a}^{b} f(x)\, d{x} $
              since $ \Prob{X=a}=\Prob{X=b}=0 $.
    \end{enumerate}
\end{Definition}

\begin{Example}{}{}
    Suppose the c.d.f.\ of $ X $ is
    \[ F(x)=\begin{dcases}
            0               & x\le a \\
            \frac{x-a}{b-a} & a<x<b  \\
            1               & x\ge b
        \end{dcases} \]
    Find the p.d.f.\ of $ X $.

    \textbf{Solution.}
    \[ f(x)=
        \begin{cases}
            \dfrac{1}{b-a} & a<x<b            \\
            0              & \text{otherwise}
        \end{cases} \]
    We note that $ X \sim \uniform{a,b} $.
\end{Example}

\begin{Example}{}{}
    Let the p.d.f.\ be defined as follows.
    \[ f(x)=\begin{dcases}
            \frac{\theta}{x^{\theta+1}} & x\ge 1 \\
            0                           & x<1
        \end{dcases} \]
    \begin{enumerate}[label=(\roman*)]
        \item For what values of $ \theta $ is $ f $ a p.d.f.
        \item Find $ F(x) $.
        \item Find $ \Prob{-2<X<3} $.
    \end{enumerate}
    \textbf{Solution.}

    \begin{enumerate}[label=(\roman*)]
        \item Note that $ \dfrac{\theta}{x^{\theta+1}} \ge 0 $
              for all $ \theta\ge 0 $.

              \underline{Case 1}: $ \theta=0 $. $ f(x)\equiv 0 $, then $ f $
              cannot be a p.d.f.\ since $ \int_{-\infty}^{\infty} f(x)\, d{x}=0\neq 1 $

              \underline{Case 2}: $ \theta>0 $.
              \[ \int_{-\infty}^{\infty} f(x)\, d{x}=\int_{-\infty}^{1} f(x)\, d{x}
                  +\int_{1}^{\infty} f(x)\, d{x}=\int_{1}^{\infty} \frac{\theta}{x^{\theta+1}}\, d{x}
                  =\Bigl[ -x^{-\theta} \Bigr]_1^\infty=1 \]

              Therefore, $ f $ is a p.d.f.\ when $ \theta>0 $.

        \item $ F(x)=\Prob{X\le x} $.

              \underline{Case 1}: $ x<1 $.
              \[ \Prob{X\le x}=\int_{-\infty}^{x} f(t)\, d{t} =0 \]

              \underline{Case 2}:  $ x\ge 1 $.
              \[ \Prob{X\le x}=\int_{-\infty}^{x} f(t)\, d{t}
                  =\int_{-\infty}^{1} f(t)\, d{t} +\int_{1}^{x} f(t)\, d{t}
                  =\int_{1}^{x} \frac{\theta}{t^{\theta+1}} \, d{t}=\Bigl[ -t^{-\theta} \Bigr]_1^x=
                  1-x^{-\theta}  \]
              Therefore,
              \[ F(x)=\begin{cases}
                      1-x^{-\theta} & x\ge 1 \\
                      0             & x< 1
                  \end{cases} \]
        \item $ \Prob{-2<X<3} $. Either use the c.d.f.\ we found or the p.d.f.

              \underline{Using the c.d.f.} we have
              \[ F(3)-F(-2)=(1-3^{-\theta})-0 \]

              \underline{Using the p.d.f.} we have
              \[ \int_{-2}^{3} f(x)\, d{x}=
                  \int_{-2}^{1} f(x)\, d{x} +\int_{1}^{3} f(x)\, d{x}
                  =\int_{1}^{3} f(x)\, d{x}=\text{exercise} \]
    \end{enumerate}

\end{Example}
