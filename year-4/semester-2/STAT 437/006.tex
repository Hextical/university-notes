\section{Why Can't We Just Use Regression? (Linear Marginal Models)}
\subsection*{Stated Mathematically}
We want to \textbf{fit a model} that gives
$ \E{Y_{ij}\given \Matrix{X}_{ij},t_{ij}} $
in terms of \textbf{interpretable parameters}.
\subsection*{Let's use an example!}
\[ \begin{array}{cccccccccc}
        \toprule
        \texttt{ID} & \texttt{Trt} & \texttt{W0} & \texttt{W1} & \texttt{W4} & \texttt{W6} & \texttt{ID} & \texttt{Trt} & \texttt{time} & W      \\
        \midrule
        1           & \texttt{P}   & 30.8        & 26.9        & 25.8        & 23.8        & 1           & \texttt{P}   & 1             & 30.8   \\
        2           & \texttt{A}   & 26.5        & 14.8        & 19.5        & 21          & 2           & \texttt{A}   & 1             & 26.5   \\
        3           & \texttt{A}   & 25.8        & 23          & 19.1        & 23.2        & 3           & \texttt{A}   & 1             & 25.8   \\
        \vdots      & \vdots       & \vdots      & \vdots      & \vdots      & \vdots      & \vdots      & \vdots       & \vdots        & \vdots \\
        98          & \texttt{A}   & 29.4        & 22.1        & 25.3        & 4.1         & 98          & \texttt{A}   & 4             & 4.1    \\
        99          & \texttt{A}   & 21.9        & 7.6         & 10.8        & 13          & 99          & \texttt{A}   & 4             & 13     \\
        100         & \texttt{A}   & 20.7        & 8.1         & 25.7        & 12.3        & 100         & \texttt{A}   & 4             & 12.3   \\
        \bottomrule
    \end{array} \]
\begin{itemize}
    \item Consider the TLC trial data, in \textbf{wide format} (left-hand side) and then in \textbf{long
              format} (right-hand side).
    \item In the right-hand side we have an outcome ($W$), with two explanatory factors
          \big($ \Set{\texttt{Trt},\texttt{time}} $\big).
          \begin{itemize}
              \item We want $ \E{W\given \texttt{Trt},\texttt{time}} $. \textbf{Is this familiar}?
          \end{itemize}
\end{itemize}
\subsection*{Using Linear Regression}
We can fit the model in R, using \texttt{lm}. \textbf{Is this valid}?
\[ \begin{tabular}{l
            S[table-format=-2.3]
            S[table-format=2.3]
            S[table-format=0.3]}
        \toprule
                                  & {Estimate} & {Std. Error} & {$\Prob{>\abs{t}}$} \\
        \midrule
        \texttt{(Intercept)}      & 26.540     & 0.9370175    & 0.0000000           \\
        \texttt{time2}            & -13.018    & 1.3251428    & 0.0000000           \\
        \texttt{time3}            & -11.026    & 1.3251428    & 0.0000000           \\
        \texttt{time4}            & -5.778     & 1.3251428    & 0.0000166           \\
        \texttt{TreatmentP}       & -0.268     & 1.3251428    & 0.8398322           \\
        \texttt{time2:TreatmentP} & 11.406     & 1.8740349    & 0.0000000           \\
        \texttt{time3:TreatmentP} & 8.824      & 1.8740349    & 0.0000035           \\
        \texttt{time4:TreatmentP} & 3.152      & 1.8740349    & 0.0933783           \\
        \bottomrule
    \end{tabular} \]
\subsection*{What does this \texttt{lm} imply about our data?}
\begin{itemize}
    \item There is a \textbf{linear conditional mean structure}:
          \begin{align*}
              \E{W_{ij}\given \texttt{Trt}_i,t_j}
               & =\beta_0+\beta_1\texttt{Trt}_i+\beta_2\Ind{t_j=2}+\beta_3\Ind{t_j=3}+\beta_4\Ind{t_j=4} \\
               & \quad+\beta_5\texttt{Trt}_i\Ind{t_j=2}
              +\beta_6\texttt{Trt}_i\Ind{t_j=3}+\beta_7\texttt{Trt}_i\Ind{t_j=4}.
          \end{align*}
    \item There is \textbf{constant variance} such as $ \Var{W_{ij}}=\sigma^2 $
          for all $ i $ and $ j $.
    \item The values of $ W_{ij} $ are \textbf{independent}. However,
          this assumption is clearly violated.
\end{itemize}
\subsection*{What makes longitudinal data special?}
Longitudinal data are characterized by \textbf{correlation} \emph{within} individuals.

TODO figure
Therefore, the previous \texttt{lm} will work \textbf{only if} we are willing
to assume that the observations are
\textbf{independent}.
\subsection*{Longitudinal Data as Multivariate Data}
How can we adapt linear regression to allow for this
association?
\begin{itemize}
    \item When the data are in \textbf{long format}, it appears that the outcomes are univariate.
    \item When the data are in \textbf{wide format}, we can view the outcome as a vector of
          outcomes, (e.g., $ \Matrix{W}=(W_0,W_1,W_4,W_6) $).
    \item The analysis of longitudinal data is \textbf{multivariate analysis}.
          \begin{itemize}
              \item This accounts for the \textbf{lack of independence} in the outcomes!
          \end{itemize}
\end{itemize}
\subsection*{Multivariate Normal}
Instead of assuming that $ Y_{ij}\sim \N{\Matrix{X}_{ij}\beta,\sigma^2} $,
what if we took
\[ \Matrix{Y}_i \sim \MVN{\Matrix{X}_i\Matrix{\beta},\Matrix{\Sigma}_i}? \]
\textbf{Recall}: The multivariate normal (MVN) has a density given by
\[ f(\Matrix{y},\Matrix{\mu},\Matrix{\Sigma})=
    \frac{1}{(2\pi)^{k/2}}\abs{\Matrix{\Sigma}}^{-1/2}
    \exp*{-\frac{1}{2}(\Matrix{y}-\Matrix{\mu})\Matrix{\Sigma}^{-1}(\Matrix{y}-\Matrix{\mu})^\top}.
\]
\subsection*{Linear Marginal Models}
\begin{itemize}
    \item In this proposal, we specify a \textbf{linear form} for the conditional mean.
          \begin{itemize}
              \item That is, $ \E{\Matrix{Y}_i\given \Matrix{X}_i}=\Matrix{X}_i \Matrix{\beta} $,
                    where $ \Matrix{X}_i $ is a matrix and $ \Matrix{Y}_i $ is a vector.
          \end{itemize}
    \item We allow for \textbf{correlation} through the individual covariance
          matrix, $ \Matrix{\Sigma}_i $.
    \item We could (theoretically) find the \textbf{MLE} under the assumption of
          multivariate normality.
\end{itemize}
\subsection*{Covariance Matrix}
Recall that $ \Cor{X,Y}=\frac{\Cov{X,Y}}{\sqrt{\Var{X}\Var{Y}}} $,
and so, re-arranging,
\[ \Cov{X,Y}=\Cor{X,Y}\sqrt{\Var{X}\Var{Y}}.\]
Moreover, recall that a variance/covariance matrix is
\[ \Cov{\Matrix{Y}_i}=
    \Matrix{\Sigma}_i=
    \begin{bmatrix}
        \Var{Y_{i1}}        & \Cov{Y_{i1},Y_{i2}} & \cdots & \Cov{Y_{i1},Y_{ip}} \\
        \Cov{Y_{i2},Y_{i1}} & \Var{Y_{i2}}        & \cdots & \Cov{Y_{i2},Y_{ip}} \\
        \vdots              & \vdots              & \ddots & \vdots              \\
        \Cov{Y_{ip},Y_{i1}} & \Cov{Y_{ip},Y_{i1}} & \cdots & \Var{Y_{ip}}
    \end{bmatrix}. \]
\subsection*{Covariance Matrix Simplification}
If \textbf{we assume} that $ \Var{Y_{ij}}=\sigma^2 $
for all $ i, j $, \emph{and} we denote $ \Cor{Y_{ij},Y_{i\ell}}=\rho_{j\ell} $
for all $ i $, then note that
\[ \Cov{Y_{ij},Y_{i\ell}}=\Cor{Y_{ij},Y_{i\ell}}\sqrt{\Var{Y_{ij}\Var{Y_{i\ell}}}}=\sigma^2\rho_{i\ell}. \]
We write
\[ \Matrix{R}(\Matrix{\rho})=\begin{bmatrix}
        \rho_{11}  & \rho_{12}  & \cdots & \rho_{1 p} \\
        \rho_{21}  & \rho_{22}  & \cdots & \rho_{2 p} \\
        \vdots     & \vdots     & \ddots & \vdots     \\
        \rho_{p 1} & \rho_{p 2} & \cdots & \rho_{p p}
    \end{bmatrix}=\begin{bmatrix}
        1          & \rho_{12}  & \cdots & \rho_{1 p} \\
        \rho_{12}  & 1          & \cdots & \rho_{2 p} \\
        \vdots     & \vdots     & \ddots & \vdots     \\
        \rho_{1 p} & \rho_{2 p} & \cdots & 1
    \end{bmatrix}. \]
With this notation,
\[ \Matrix{\Sigma}_i=\sigma^2\Matrix{R}(\Matrix{\rho}). \]
\subsection*{Linear Marginal Models}
\textbf{Under the previous specification} we can find the MLE to be
\[ \hat{\Vector{\beta}}=
    \biggl(\sum_{i=1}^{n}\Matrix{X}_i^\top \Matrix{R}_i^{-1}\Matrix{X}_i\biggr)^{-1}
    \sum_{i=1}^{n}\Matrix{X}_i^\top \Matrix{R}_i^{-1}\Matrix{Y}_i. \]
For the variance parameter, we get
\[ \sigma^2=\frac{1}{nk}
    \sum_{i=1}^{n}(\Matrix{Y}_i-\Matrix{X}_i \Matrix{\beta})^\top
    \Matrix{R}_i^{-1}(\Matrix{Y}_i-\Matrix{X}_i \Matrix{\beta}), \]
then we can solve numerically for $ \Matrix{R}_i $.
We want to model $ \E{Y_{ij}\given \Matrix{X}_i} $ (for some purpose)
and so we specify a \textbf{multivariate linear
    model}. By assuming that the variance \textbf{is constant across different times}, and we
can accommodate the correlation expected within each individual.

The multivariate normality assumption gives us a process for computing the MLE,
which can produce estimates for the parameters of interest, denoted
$ \hat{\Vector{\beta}} $.
\subsection*{Next Steps}
\begin{itemize}
    \item How can we conduct \textbf{inference} on the estimated parameters? (Why do we want
          to?)
    \item How can we specify \textbf{time trends} in the model for the mean?
    \item How can we use this model to answer \textbf{scientific questions of interest}?
    \item What can we do about the \textbf{correlation matrix}? (Are there any shortcomings with
          our assumptions?)
\end{itemize}
\subsection*{Asymptotic Normality}
It can be shown that, asymptotically
\[ \hat{\Vector{\beta}}
    \sim \MVN[\big]{\Matrix{\beta},\Var{\hat{\Vector{\beta}}}}, \]
where
\[ \Var{\hat{\Vector{\beta}}}=
    \biggl(\frac{1}{\sigma^2}\sum_{i=1}^{n}\Matrix{X}_i^{-1}\Matrix{R}_i^{-1}\Matrix{X}_i\biggr), \]
which can be estimated by plugging in $ \hat{\sigma}^2 $ and $ \hat{\Vector{\rho}} $.
We get
\[ \se{\hat{\beta}_j}=\Bigl[\estVar{\hat{\Vector{\beta}}}\Bigr]^{1/2}_{(j,j)}. \]
\subsection*{Inference based on Wald Statistics}
As a result,
\[ \frac{\hat{\beta}_j-\beta_j}{\se{\hat{\beta}_j}}\sim \N{0,1}. \]
This can be used to test $ \HN $: $ \beta_j=\beta^\star $, or for confidence intervals,
\textbf{just like with linear regression}! An equivalent expression is
\[ \frac{(\hat{\beta}_j-\beta_j)^2}{\Var{\hat{\beta}_j}}\sim \chi^2_1. \]
\subsection*{Time as a Covariate}
\begin{itemize}
    \item Generally speaking, we can simply include \textbf{time} as a \textbf{covariate} in the model.
    \item If the data are \textbf{balanced} and there are \emph{relatively few} time points, we can include it
          as a factor.
    \item If the data are \textbf{not balanced} or there are \emph{too many} time points, we can include it
          as a continuous variable.
          \begin{itemize}
              \item We can also include \textbf{quadratic} time trends, or \textbf{logarithmic} time trends, or any other
                    functional form.
          \end{itemize}
    \item We can include time as \textbf{calendar time}, \textbf{time since baseline}, \textbf{index of time point}, \textbf{age}, etc.
          \begin{itemize}
              \item This will depend on what we have \textbf{measured} and what we are \textbf{interested} in.
          \end{itemize}
\end{itemize}
The \textbf{choice} of how we include time will be dictated \textbf{both} by the \emph{available} data,
and by the \textbf{scientific questions of inquiry}.
This goes for the \textbf{form} it takes in the model, and the \textbf{timescale} that we choose
to use.