\makeheading{Week 2}{\daterange{2022-01-10}{2022-01-14}}%chktex 8
\section*{Survey Samples}
\begin{Regular}{}
      A \textbf{survey sample} $S$, is a subset of the population
      $ U=\Set{1,2,\ldots,N} $.
      \tcblower{}
      The sample size $ n=\abs{S} $ is the number
      of units in the sample (a set of $ n $ ``unordered'' units):
      \[ S=\Set{i_1,i_2,\ldots,i_n}. \]
      We could simply use $ S=\Set{1,2,\ldots,n} $.
\end{Regular}
\begin{Example}{Survey Sample}
      If $ N=10 $ and $n=3 $, then $U=\Set{1,2,3,4,5,6,7,8,9,10}$,
      and some possible samples are:
      \begin{itemize}
            \item $S=\Set{7,4,9}=\Set{i_1,i_2,i_3}$, or
            \item $S=\Set{1,2,3}$.
      \end{itemize}
\end{Example}
\section*{Non-probability Samples versus Probability Samples}
\begin{Regular}{}
      \textbf{Non-probability samples} are selected by subjective or any
      convenient methods.
      \tcblower{}
      We will list some examples of non-probability sampling.
      \begin{itemize}
            \item \textbf{Quota sampling}: The sample is obtained by a number of
                  interviewers, each of whom is required to sample certain
                  numbers of units with certain types or characteristics. How to
                  select the units is completely left in the hands of the interviewers.
            \item \textbf{Judgement or purposive sampling}: The sample is selected based
                  on what the sampler believes to be ``typical'' or ``most
                  representative'' of the population.
            \item \textbf{Restricted sampling}: The sample is restricted to certain parts of
                  the population which are readily accessible.
            \item \textbf{Sample of convenience}: The sample is taken from those who are
                  easy to reach.
            \item \textbf{Sample of volunteers}: The sample consists of those who
                  volunteer to participate.
            \item \textbf{Web panels}: The sample is selected from a panel of people who
                  signed up to do surveys in order to receive cash or other
                  incentives.
      \end{itemize}
      \underline{Remarks}:
      \begin{itemize}
            \item The most serious issue with non-probability survey samples is that
                  the sample is \emph{biased}. A sample is \textbf{biased}
                  if it has unknown inclusion probabilities.
            \item Non-probability survey samples are not the focus of this course. But
                  the topic is becoming important in recent years, since data from
                  non-probability survey samples become useful sources.
            \item Yilin Chen's PhD thesis research is on statistical analysis with
                  non-probability survey samples, to be introduced in the last lecture.
      \end{itemize}
\end{Regular}
\begin{Regular}{}
      \textbf{Probability samples}, theoretically speaking, are selected through a
      probability measure over a pool of candidate samples.
      \begin{itemize}
            \item Let $ \Omega=\Set{S\given S\subseteq U} $
                  be the set of all possible subsets of the survey population $U$.
            \item Let $ \mathcal{P} $ be a probability measure over $ \Omega $ such that
                  \begin{enumerate}[(i)]
                        \item $ \mathcal{P}(S)\ge 0 $ for any $ S\in \Omega $, and
                        \item $ \sum_{\Set{S\given S\in\Omega}}\mathcal{P}(S)=1 $
                  \end{enumerate}
      \end{itemize}
      A probability sample $ S $ is selected based on the \textbf{probability sampling design}, $ \mathcal{P} $.
\end{Regular}
\begin{Example}{}
      \textbf{Example 1.4}. If $ N=3 $ and $ U=\Set{1,2,3} $, then we have seven possible
      candidate samples.
      \tcblower{}
      \begin{itemize}
            \item $ n=1 $: $ S_1=\Set{1} $, $ S_2=\Set{2} $, $ S_3=\Set{3} $.
            \item $ n=2 $: $ S_4=\Set{1,2} $, $ S_5=\Set{1,3} $, $ S_6=\Set{2,3} $.
            \item $ n=3 $: $ S_7=\Set{1,2,3} $ (census).
      \end{itemize}
      \[ \begin{NiceArray}{c|ccccccc}
                  S              & S_1 & S_2 & S_3 & S_4 & S_5 & S_6 & S_7 \\
                  \midrule
                  \mathcal{P}(S) & 1/6 & 1/6 & 1/6 & 1/6 & 1/6 & 1/6 & 0   \\
                  \midrule
                  \mathcal{P}(S) & 0   & 0   & 0   & 1/3 & 1/3 & 1/3 & 0   \\
                  \midrule
                  \mathcal{P}(S) & 0   & 0   & 0   & 1/2 & 1/4 & 1/4 & 0
            \end{NiceArray} \]
      Note that we have $ \mathcal{P}(S)\ge 0 $ for any $ S\in \Omega $ and
      $ \sum_{\Set{S\given S\in\Omega}}\mathcal{P}(S)=1 $.

      To select a sample under design 2, we first generate
      a random number $ R $ from the uniform distribution over $ [0,1] $.
      If $ 0\le R\le 1/3 $, $ S_4 $ is selected; if $ 1/3<R\le 2/3 $,
      $ S_5 $ is selected; if $ 2/3<R\le 1 $, $ S_6 $ is selected.
\end{Example}
\begin{Regular}{}
      A sampling design $ \mathcal{P} $ has a fixed sample size $ n $ if
      $ \mathcal{P}(S)=0 $ for any $ S $ such that
      $ \abs{S}\ne n $. That is, the probability measure is defined over the set
      \[ \Omega_n=\Set{S\given S\subseteq U\text{ and }\abs{S}=n}. \]
\end{Regular}
\subsection*{Discrete Random Number Generator for Sample Selection (Problem 1.4)}
\begin{Example}{}
      Let $ X \sim f(x) $ such that $p_i=f(x_i)=\Prob{X=x_i},i=1,2,\ldots$.
      \begin{itemize}
            \item \emph{Step 1}. Probability cumulation.
                  \begin{align*}
                        b_0 & =0                 \\
                        b_1 & =p_1               \\
                        b_2 & =p_1+p_2           \\
                        b_3 & =p_1+p_2+p_3       \\
                            & \vdotswithin{=}    \\
                        b_j & =\sum_{i=1}^{j}p_i \\
                            & \vdotswithin{=}
                  \end{align*}
            \item \emph{Step 2}. Generate $ R\sim U(0,1) $.
            \item \emph{Step 3}. Let $ X^\star=x_j $ if $ b_{j-1}<R\le b_j $.
      \end{itemize}
      Show that $ X^\star $ has the same distribution as $ X $.
      \tcblower{}
      \textbf{Solution}: Not completed.
\end{Example}
\subsection*{Survey Variables}
\begin{Regular}{}
      \begin{itemize}
            \item $ y $: the response variable; $ \Vector{x} $
                  the vector of auxiliary variables.
            \item $ (y_i;\Vector{x}_i) $: the values of $ (y,\Vector{x}) $
                  associated with unit $ i $, $ i=1,2,\ldots,N $.
            \item A common assumption in survey sampling: the values $ (y_i,\Vector{x}_i) $
                  can be measured without error if $ i $ is selected in the sample.
      \end{itemize}
\end{Regular}
\subsection*{Population Parameters}
\begin{Regular}{}
      \begin{itemize}
            \item \textbf{Population totals}:
                  \[ T_y=\sum_{i=1}^{N}y_i\quad\text{ and }\quad T_{\Vector{x}}=\sum_{i=1}^{N}\Vector{x}_i. \]
            \item \textbf{Population means}:
                  \[ \mu_y=\frac{1}{N}\sum_{i=1}^{N}y_i\quad\text{ and }\quad \mu_{\Vector{x}}=\frac{1}{N}\sum_{i=1}^{N}\Vector{x}_i. \]
            \item \textbf{Population variance} of $ y $:
                  \[ \sigma_y^2=\frac{1}{N-1}\sum_{i=1}^{N}(y_i-\mu_y)^2
                        =\frac{1}{N-1}\biggl(\sum_{i=1}^{N}y_i^2-N\mu_y^2\biggr). \]
      \end{itemize}
\end{Regular}
\begin{Regular}{}
      An important special case is when $y$ is an indicator variable:
      \[ y_i=\begin{cases}
                  1, & \text{if unit $ i $ has attribute ``$A$''}, \\
                  0, & \text{otherwise}.
            \end{cases} \]
      \begin{itemize}
            \item Let $ N $ be the total number of units in the population (population size).
            \item Let $ M $ be the total number of units in the population having attribute ``$A$.''
      \end{itemize}
      \tcblower{}
      We can define our population parameters in terms of the new indicator variable.
      \begin{itemize}
            \item Population total:
                  \[ T_y=\sum_{i=1}^{N}y_i=M. \]
            \item Population mean:
                  \[ \mu_y=\frac{T_y}{N}=\frac{M}{N}=P, \]
                  where $ P $ is the population proportion of units with attribute ``A.''
            \item Population variance:
                  \begin{align*}
                        \sigma_y^2
                         & =\frac{1}{N-1}\biggl(\sum_{i=1}^{N}y_i^2-N\mu_y^2\biggr)                                 \\
                         & =\frac{1}{N-1}(M-NP^2)                                                                   \\
                         & =\frac{N}{N-1}P(1-P)                                                                     \\
                         & \approx P(1-P)                                           &  & \text{ if $ N $ is large}.
                  \end{align*}
      \end{itemize}
\end{Regular}
\subsection*{Probability Sampling and Design-based Inference}
\begin{Regular}{}
      \begin{itemize}
            \item The survey population $ U=\Set{1,2,\ldots,N} $ is viewed as fixed.
            \item The values $ y_i $ and $ \Vector{x}_i $ attached to unit $ i $
                  and the population parameters such as $ T_y $ and $ \mu_y $
                  are also viewed as fixed.
            \item The values of the population parameters can be determined without error by conducting
                  a census.
            \item The sample $ S $ is selected according to a probability sampling design $ \mathcal{P} $.
            \item The sample $ S $ is a random set under $ \mathcal{P} $.
            \item Each unit in the population has a probability to be included in the
                  sample.
            \item Randomization is induced by the probability sampling design for
                  the selection of the survey sample.
      \end{itemize}
\end{Regular}
\subsection*{Basic Sampling Techniques and Advanced Topics}
\begin{itemize}
      \item Basic sampling techniques and theory are developed for the
            estimation of the population total $T_y$ and the population mean $ \mu_y $.\\
            (Chapters 1--5 in the textbook)
      \item The basic methods and theory can be extended to handle more
            advanced topics, such as design-based regression analysis using
            survey data.\\
            (Chapters 6--11 in the textbook)
\end{itemize}
\chapter{Review of Simple Random Sampling}
\section{Simple Random Sampling Without Replacement (SRSWOR)}
\begin{Regular}{}
      \underline{Task}: Select a sample of size $n$ from a population of size $N$ with
      equal probability among all candidate samples.
\end{Regular}
\begin{Regular}{}
      The total number of candidate samples is
      \[ \binom{N}{n}=\frac{N(N-1)\cdots(N-n+1)}{n!}. \]
      The \textbf{probability measure} for the sampling design is
      \begin{align*}
            \mathcal{P}(S)
             & =\begin{cases}
                      \frac{1}{\binom{N}{n}}, & \text{if $\abs{S}=n$}     \\
                      0,                      & \text{if $\abs{S}\ne n$}.
                \end{cases}
      \end{align*}
      \tcblower{}
      \underline{Remark}: $ \mathcal{P}(S) $ is a theoretical tool. That is,
      $ \mathcal{P}(S) $ cannot be used to select a sample in practice. For example,
      if $ N=1000 $ and $ n=3 $, then
      \[ \binom{N}{n}=\frac{1000\times 999\times 998}{6}=166\,167\,000. \]
\end{Regular}
\subsection*{Sampling Scheme/Procedure}
\begin{Regular}{}
      \begin{itemize}
            \item Select the survey sample through a sequential draw-by-draw method;
                  select units from the sampling frame, one-at-a-time, until the final
                  sample is chosen.

            \item \textbf{SRSWOR} is a sampling procedure to select a sample of size $n$ with
                  equal probability among all candidate samples.

            \item \textbf{The sampling frame for SRSWOR}:
                  A complete list of $N$ units in the population.
      \end{itemize}
\end{Regular}
\subsection*{SRSWOR Sampling Procedure}
\begin{Regular}{}
      \begin{enumerate}[(1)]
            \item Select the first unit from the $N$ units on the sampling frame with
                  equal probabilities $1/N$; denote the selected unit as $i_1$;
            \item Select the second unit from the remaining $ N-1 $ units on the
                  sampling frame with equal probabilities $ 1/(N-1) $; denote the
                  selected unit as $i_2$;
            \item Continue the process and select the $n\textsuperscript{th}$ unit from the remaining
                  $ N-n+1 $ units on the sampling frame with equal probabilities
                  $ 1/(N-n+1) $; denote the selected unit as $ i_n $.
      \end{enumerate}
\end{Regular}
Let $ S=\Set{i_1,i_2,\ldots,i_n} $ be the final sample.
\[ \mathcal{P}(S)=\frac{n(n-1)\cdots(2)(1)}{N(N-1)\cdots(N-n+1)}=\frac{1}{\binom{N}{n}}. \]
\begin{Result}{}
      \textbf{Theorem 2.1}. Under simple random sampling without replacement,
      the selected sample satisfies the probability measure $ \mathcal{P} $ specified as
      \[ \ProbM{S}=\begin{cases}
                  1/\binom{N}{n}, & \text{if $ \abs{S}=n $}, \\
                  0,              & \text{otherwise}.
            \end{cases} \]
      \tcblower{}
      \textbf{Proof}: Not given.
\end{Result}
\begin{itemize}
      \item Survey sample selection always focuses on units, that is, the labels.
      \item Survey sample data: $ \Set{(y_i,x_i),i\in S} $.
\end{itemize}
\begin{Regular}{}
      The \textbf{sample mean} is defined by
      \[ \bar{y}=\frac{1}{n}\sum_{i\in S}y_i. \]
      The \textbf{sample variance} is defined by
      \[ s_y^2=\frac{1}{n-1}\sum_{i\in S}(y_i-\bar{y})^2=\frac{1}{n-1}\biggl(\sum_{i\in S}y_i^2-n(\bar{y})^2\biggr). \]
      \tcblower{}
      \underline{Remarks}:
      \begin{itemize}
            \item The sample mean $ \bar{y} $ and $ s_y^2 $ are useful
                  statistics under simple random sampling, but not necessarily under
                  other sampling methods.
            \item The notation $ \sum_{i\in S} $ is preferred over
                  $ \sum_{i=1}^{n} $.
            \item The form of estimators for population parameters depends on the
                  sampling methods.
            \item The combination of ``sampling design'' and ``estimation method''
                  is called a ``\emph{sampling strategy}'' (Thompson, 1997; Rao, 2005).
      \end{itemize}
\end{Regular}
\subsection*{Expectation and Variance Under Design-based Inferences}
\begin{Regular}{}
      In classic statistics: $ X_1,X_2,\ldots,X_n $ are iid with $ \E{X_i}=\mu $,
      $ \V{X_i}=\sigma^2 $. Let $ \bar{X}=\frac{1}{n}\sum_{i=1}^{n}X_i $.
      \begin{itemize}
            \item \textbf{Sample mean}:
                  \[ \E{\bar{X}}=\frac{1}{n}\sum_{i=1}^{n}\E{X_i}=\frac{1}{n}\sum_{i=1}^{n}\mu=\mu. \]
            \item \textbf{Sample variance}:
                  \[ \V{\bar{X}}=\frac{1}{n^2}\sum_{i=1}^{n}\V{X_i}=\frac{1}{n^2}\sum_{i=1}^{n}\sigma^2=\frac{\sigma^2}{n}. \]
      \end{itemize}
      \tcblower{}
      However, in SRSWOR, note that
      \[ \E{\bar{y}}=\E*{\frac{1}{n}\sum_{i\in S}y_i}\ne \frac{1}{n}\sum_{i\in S}\E{y_i}. \]
      \begin{itemize}
            \item $ S $: a random set.
            \item $ \sum_{i\in S} $: a random ``sum.''
            \item $ y_i $: a fixed quantity for the given $ i $.
      \end{itemize}
\end{Regular}
\begin{Result}{}
      \textbf{Theorem 2.2} Under SRSWOR:
      \begin{enumerate}[(a)]
            \item The sample mean $ \bar{y}=n^{-1}\sum_{i\in S}y_i $
                  is a design-unbiased estimator for the population
                  mean $ \mu_y=N^{-1}\sum_{i=1}^{N}y_i $, that is,
                  \[ \E{\bar{y}}=\mu_y. \]
            \item The design-based variance of $ \bar{y} $
                  under SRSWOR is given by
                  \[ \V{\bar{y}}=\biggl(1-\frac{n}{N}\biggr)\frac{\sigma_y^2}{n}, \]
                  where $ \sigma_y^2 $ is the population variance. The term
                  $ (1-n/N) $ is called the \textbf{finite population correction} (fpc)
                  factor; The ratio $ n/N $ is called the \textbf{sampling fraction}.
            \item An unbiased variance estimator for $ \bar{y} $ is given by
                  \[ v(\bar{y})=\biggl(1-\frac{n}{N}\biggr)\frac{s_y^2}{n}, \]
                  which satisfies
                  $ \E{v(\bar{y})}=\V{\bar{y}} $,
                  where
                  \[ \V{\bar{y}}=\biggl(1-\frac{n}{N}\biggr)\frac{\sigma_y^2}{n}. \]
                  Furthermore, the sample variance $ s_y^2 $ is an unbiased estimator for the
                  population variance $ \sigma_y^2 $ under SRSWOR, i.e.,
                  $ \boxed{\E{s_y^2}=\sigma_y^2} $, where
                  \begin{align*}
                        s_y^2
                         & =\frac{1}{n-1}\biggl(\sum_{i\in S}y_i^2-n(\bar{y})^2\biggr) \\
                         & =\frac{n}{n-1}\biggl(\frac{1}{n}\sum_{i\in S}y_i^2\biggr)
                        -\frac{n}{n-1}(\bar{y})^2.
                  \end{align*}
      \end{enumerate}
      \tcblower{}
      \textbf{Proof}.
      \begin{enumerate}[(a)]
            \item \begin{itemize}
                        \item \emph{Method 1}. Use the probability measure $ \mathcal{P}(S) $
                              for the survey design, that is, $ \mathcal{P}(S)=\frac{1}{\binom{N}{n}} $
                              for $ \abs{S}=n $.

                              Also, $ \bar{y} $ depends only on $ S $.
                              \[ \bar{y}=\frac{1}{n}\sum_{i\in S}y_i=\bar{y}(S), \]
                              that is, $ \bar{y} $ is a function of $ S $.
                              \begin{align*}
                                    \E{\bar{y}}
                                     & =\sum(\text{value})(\text{prob})                                                  \\
                                     & =\sum_S \bar{y}(S)\mathcal{P}(S)                                                  \\
                                     & =\sum_{S:\abs{S}=n}\frac{1}{n}\sum_{i\in S}y_i \frac{1}{\binom{N}{n}}             \\
                                     & =\frac{1}{n}\frac{1}{\binom{N}{n}}\sum_{\Set{S\given \abs{S}=n}} \sum_{i\in S}y_i \\
                                     & =\frac{1}{n}\frac{1}{\binom{N}{n}}\sum_{i=1}^{N}t_i y_i                           \\
                                     & =\frac{1}{N}\sum_{i=1}^{N}y_i                                                     \\
                                     & =\mu_y,
                              \end{align*}
                              where $ t_i = $ number of $S$ which includes the unit $ i $:
                              \[ t_i=\binom{N-1}{n-1}. \]
                              \begin{Example}{}
                                    $ N=3 $, $ n=2 $: $ S_1=\Set{1,2} $, $ S_2=\Set{1,3} $, $ S_3=\Set{2,3} $.
                                    \begin{align*}
                                          \sum_{\Set{S\given\abs{S}=2}} \sum_{i\in S}y_i
                                           & =(y_1+y_2)+(y_1+y_3)+(y_2+y_3) \\
                                           & =2 y_1+2y_2+2y_3.
                                    \end{align*}
                              \end{Example}
                        \item \emph{Method 2}. Use the sampling scheme, the sequential
                              draw-by-draw procedure. Let $ Z_k $ be the $ y $-value from the
                              $ k\textsuperscript{th} $ draw:
                              \begin{itemize}
                                    \item $ S=\Set{i_1,i_2,\ldots,i_n} $.
                                    \item $ Z_k=y_{ik} $ for $k=1,2,\ldots,n$.
                                    \item $ \bar{y}=\frac{1}{n}\sum_{i\in S}y_i=\frac{1}{n}\sum_{k=1}^{n}Z_k $.
                              \end{itemize}
                              Hence,
                              \[ \E{\bar{y}}=\E*{\frac{1}{n}\sum_{k=1}^n Z_k}
                                    =\frac{1}{n}\sum_{k=1}^{n}\E{Z_k}. \]
                              What's the probability function of $ Z_k $?
                              \[ \begin{NiceArray}{c|cccc}
                                          Z_k          & y_1 & y_2 & \cdots & y_N \\
                                          \midrule
                                          f(\:\cdot\:) & 1/N & 1/N & \cdots & 1/N
                                    \end{NiceArray} \]
                              Therefore,
                              \[ \E{Z_k}=\sum_{i=1}^{N}y_i \frac{1}{N}=\mu_y. \]
                        \item \emph{Method 3}. Use the sample inclusion indicator variables.
                              \[ A_i=\begin{cases}
                                          1, & \text{if $ i\in S $},    \\
                                          0, & \text{if $ i\notin S $}.
                                    \end{cases}\qquad i=1,2,\ldots,N. \]
                              The $ A_i $'s are random variables.
                              \begin{align*}
                                    \Prob{A_i=1} & =p=\Prob{i\in S}=\frac{1\times \binom{N-n}{n-1}}{\binom{N}{n}}=\frac{n}{N}. \\
                                    \Prob{A_i=0} & =1-p.                                                                       \\
                                    \E{A_i}      & =p=\frac{n}{N}.                                                             \\
                                    \V{A_i}      & =p(1-p)=\frac{n}{N}\biggl(1-\frac{n}{N}\biggr).                             \\
                                    \E{\bar{y}}  & =\E*{\frac{1}{n}\sum_{i\in S}y_i}                                           \\
                                                 & =\E*{\frac{1}{n}\sum_{i=1}^{N}A_i y_i}                                      \\
                                                 & =\frac{1}{n}\sum_{i=1}^{n}y_i\E{A_i}                                        \\
                                                 & =\frac{1}{N}\sum_{i=1}^{N}y_i                                               \\
                                                 & =\mu_y.
                              \end{align*}
                  \end{itemize}
            \item This result can be proved using different methods. Use the indicator variables:
                  \begin{align*}
                        \V{\bar{y}}
                                      & =\V*{\frac{1}{n}\sum_{i=1}^{N}A_i y_i}                 \\
                                      & =\frac{1}{n^2}\biggl[\sum_{i=1}^{N}y_i^2\V{A_i}+
                        \sum_i\sum_j y_iy_j\Cov{A_i,A_j}\biggr]                                \\
                        \V{A_i}       & =\frac{n}{N}\biggl(1-\frac{n}{N}\biggr).               \\
                        \Cov{A_i,A_j} & =\E{A_iA_j}-\E{A_i}\E{A_j}.                            \\
                        \E{A_iA_j}    & =\sum_i\sum_j a_ia_j \Prob{A_i=a_i}\Prob{A_j=a_j}      \\
                                      & =\Prob{A_i=1,A_j=1}                                    \\
                                      & =\Prob{i\in S,j\in S}                                  \\
                                      & =\frac{1\times 1\times \binom{N-2}{n-2}}{\binom{N}{n}} \\
                                      & =\frac{n(n-1)}{N(N-1)}.
                  \end{align*}
                  Therefore,
                  \[ \boxed{\Cov{A_i,A_j}=\frac{n(n-1)}{N(N-1)}-\biggl(\frac{n}{N}\biggr)^2=\frac{n(n-N)}{N^2(N-1)}}. \]
                  \[ \boxed{\mu_y^2=\frac{1}{N^2}\biggl(\sum_{i=1}^{N}y_i\biggr)^2=\frac{1}{N^2}\sum_{i}\sum_{j}y_iy_j
                              =\frac{1}{N^2}\biggl[\sum_{i=1}^{N}y_i^2+\sum_{i}\sum_{j}y_iy_j\biggr]}. \]
                  \[ \boxed{\sigma_y^2=\frac{1}{N-1}\biggl(\sum_{i=1}^{N}y_i^2-N\mu_y^2\biggr)} \]
                  \begin{align*}
                        \V{\bar{y}}
                         & =\V*{\frac{1}{n}\sum_{i=1}^{N}A_i y_i}                                                                                      \\
                         & =\frac{1}{n^2}\Biggl(\sum_{i=1}^{N}y_i^2\V{A_i}+
                        \sum_{i}\sum_{j}y_iy_j\Cov{A_i,A_j}\biggr)                                                                                     \\
                         & =\frac{1}{n^2}\Biggl(\sum_{i=1}^{N}y_i^2\frac{n}{N}\biggl(\overbrace{1-\frac{n}{N}}^{-\frac{n-N}{N}}\biggr)+
                        \sum_{i}\sum_{j}y_iy_j\frac{n(n-N)}{N^2(N-1)}\biggr)                                                                           \\
                         & =\frac{n-N}{n(N-1)N^2}\biggl(-N\sum_{i=1}^{N}y_i^2+\underbrace{\sum_{i=1}^{N}y_i^2+\sum_i\sum_j y_iy_j}_{N^2\mu_y^2}\biggr) \\
                         & =\frac{n-N}{n(N-1)N^2}(-N)\underbrace{\biggl(\sum_{i=1}^{N}y_i^2-N\mu_y^2\biggr)}_{\sigma_y^2(N-1)}                         \\
                         & =\frac{n-N}{n(N-1)N^2}(-N)\sigma_y^2(N-1)                                                                                   \\
                         & =\frac{n-N}{N^2}(-N)\frac{\sigma_y^2}{n}                                                                                    \\
                         & =\frac{N-n}{N}\frac{\sigma_y^2}{n}                                                                                          \\
                         & =\biggl(1-\frac{n}{N}\biggr)\frac{\sigma_y^2}{n}.
                  \end{align*}
            \item Homework.
      \end{enumerate}
\end{Result}
\subsection*{Summary}
\begin{Regular}{}
      \begin{itemize}
            \item The population mean $ \mu_y $ and the population variance
                  $ \sigma_y^2 $ are fixed (but unknown) population parameters.
            \item The sample mean $ \bar{y} $ and the sample variance $ s_y^2 $
                  are random variables under the survey design.
            \item The $ \bar{y} $ is an unbiased estimator $ \mu_y $: $ \E{\bar{y}}=\mu_y $.
            \item $ \V{\bar{y}}=\biggl(1-\frac{n}{N}\biggr)\frac{\sigma_y^2}{n} $
                  is the theoretical variance of $ \bar{y} $ and is a fixed, but unknown
                  quantity depending on the population variance $ \sigma_y^2 $.
            \item $ v(\bar{y})=\biggl(1-\frac{n}{N}\biggr)\frac{s_y^2}{n} $
                  is unbiased estimator for $ \bar{y} $ (computable with the given sample data).
            \item The population size $ N $ is known under SRSWOR\@. (As part of the sampling
                  frame information).
      \end{itemize}
\end{Regular}
\begin{Example}{}
      The R function for SRSWOR and SRSWR (next section) with
      specified $N$ and $n$: \texttt{sample(N,n)}
      %\begin{noindent}
      <<>>=
      N=10
      n=4
      sam=sample(N,n)
      sam
      sam=sample(N,n,replace=T)
      sam
      N=100
      n=4
      sam=sample(N,n)
      sam
      sam=sample(N,n,replace=T)
      sam
      @
%\end{noindent}
\end{Example}