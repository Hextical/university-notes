\makeheading{Week 10}{\daterange{2021-11-08}{2021-11-12}}
\section*{Topic 3e: Log Linear Models for Two-way Tables}
\addcontentsline{toc}{section}{Topic 3e: Log Linear Models for Two-way Tables}
\subsubsection*{Likelihood Based Analysis of 2-way Contingency Tables}
\[ \begin{NiceArray}{c|ccccccc|c}[first-row,first-col]
                                           &        & \Block{1-7}{\text{Factor $ W $}}                                                                                                        \\
                                           &        & 1                                & 2             & 3             & \cdots & j             & \cdots & J                                  \\
            \midrule
            \Block{7-1}{\text{Factor $V$}} & 1      & y_{11}                           & y_{12}        & y_{13}        & \cdots & y_{1j}        & \cdots & y_{1J}        & y_{1\bullet}       \\
                                           & 2      & y_{21}                           & y_{22}        & y_{23}        & \cdots & y_{2j}        & \cdots & y_{2J}        & y_{2\bullet}       \\
                                           & 3      & y_{31}                           & y_{32}        & y_{33}        & \cdots & y_{3j}        & \cdots & y_{3J}        & y_{3\bullet}       \\
                                           & \vdots & \vdots                           & \vdots        & \vdots        & \ddots & \vdots        & \ddots & \vdots        & \vdots             \\
                                           & i      & y_{i1}                           & y_{i2}        & y_{i3}        & \cdots & y_{ij}        & \cdots & y_{iJ}        & y_{i\bullet}       \\
                                           & \vdots & \vdots                           & \vdots        & \vdots        & \ddots & \vdots        & \ddots & \vdots        & \vdots             \\
                                           & I      & y_{I1}                           & y_{I2}        & y_{I3}        & \cdots & y_{Ij}        & \cdots & y_{IJ}        & y_{I\bullet}       \\
            \midrule
                                           &        & y_{\bullet 1}                    & y_{\bullet 2} & y_{\bullet 3} & \cdots & y_{\bullet j} & \cdots & y_{\bullet J} & y_{\bullet\bullet}
      \end{NiceArray}. \]
\begin{itemize}
      \item Previously: Previously: Derived Likelihood Ratio/Deviance tests for testing for \textcolor{Blue}{independence}
            between Factor $V$ and Factor $W$.
      \item \textcolor{Blue}{Basic Assumption}: $ Y_{ij} \sim \POI{\mu_{ij}} $, $ \forall i,j $.
      \item When we condition on the Grand Total the joint distribution becomes Multinomial,
            and we want to test:
            \[ \HN\colon \pi_{ij}=\pi_{i\bullet}\pi_{\bullet j}\;\forall i,j \]
            \[ \HA\colon \pi_{ij}\ne \pi_{i\bullet}\pi_{\bullet j}\;\text{for some } i,j. \]
      \item When we condition on the Row Totals the joint distribution becomes \textcolor{Blue}{Product
                  Multinomial}, and we want to test:
            \[ \HN\colon \pi_{1j}=\pi_{2j}=\cdots=\pi_{Ij}=\pi_j,\;j=1,2,\ldots,J, \]
            \[ \HA\colon \text{at least one }\pi_{ij}\ne \pi_{i^\prime j}. \]
      \item In either case, the \textcolor{Blue}{Likelihood Ratio/Deviance Test} statistic is:
            \[ D=2\sum_i\sum_j y_{ij}\log*{\frac{y_{ij}}{y_{i\bullet}y_{\bullet j}/y_{\bullet\bullet}}} \sim \chi^2_{(I-1)(J-1)}\text{ under $ \HN $}.\]
\end{itemize}
\subsection*{Log Linear Models for 2-way Contingency Tables}
\addcontentsline{toc}{subsection}{Log Linear Models for 2-way Tables}
\begin{itemize}
      \item \textcolor{Blue}{Basic Assumption}: $ Y_{ij} \sim \POI{\mu_{ij}} $, $ \forall i,j $.
      \item \textcolor{Blue}{Explanatory Variables}: Factor $V$ and $W$:
            \[ \begin{array}{cc}
                        \begin{aligned}
                              x_1     & =\Ind{\text{Factor $V$ at level 2}}, \\
                              x_2     & =\Ind{\text{Factor $V$ at level 3}}, \\
                                      & \vdotswithin{=}                      \\
                              x_{I-1} & =\Ind{\text{Factor $V$ at level I}}, \\
                        \end{aligned} &
                        \begin{aligned}
                              x_I       & =\Ind{\text{Factor $W$ at level 2}}, \\
                              x_{I+1}   & =\Ind{\text{Factor $W$ at level 3}}, \\
                                        & \vdotswithin{=}                      \\
                              x_{I+J-2} & =\Ind{\text{Factor $W$ at level J}}. \\
                        \end{aligned}
                  \end{array} \]
      \item The main effects log-linear model would be:
            \begin{align*}
                  \log{\mu_\ell}
                   & =\beta_0+\overbrace{\beta_1x_{1\ell}+\beta_2x_{2\ell}+\cdots+\beta_{I-1}x_{I-1\ell}}^{\text{Factor $V$}}+                               \\
                   & \quad+\underbrace{\beta_Ix_{I\ell}+\beta_{I+1}x_{I+1\ell}+\cdots+\beta_{I+J-2}x_{I+J-2\ell}}_{\text{Factor $W$}} &  & \ell=1,\ldots,IJ.
            \end{align*}
      \item Note: $ \text{\# parameters}=1+(I-1)+(J-1)=I+J-1 $.
      \item The $ \Vector{x}^\top \Vector{\beta} $ is quite cumbersome when $ I $ and $ J $ are large.
      \item Consider the following expression for the model:
            \[ \log{\mu_{ij}}=u+u_i^V+u_j^W,\;i=1,\ldots,I,\,j=1,\ldots,J, \]
            where $ u_1^V+u_1^W=0 $.
      \item Note: $ \text{\# parameters}=1+(I-1)+(J-1)=I+J-1 $.
      \item This notation suppresses the binary $ x $ variables.
      \item The relationship between the $ \beta $ and $ u $ is as follows:
            \[ \begin{array}{ccc}
                        u=\beta_0,                 &
                        \begin{aligned}
                              u_2^V & =\beta_1,       \\
                              u_3^V & =\beta_2,       \\
                                    & \vdotswithin{=} \\
                              u_I^V & =\beta_{I-1},
                        \end{aligned} &
                        \begin{aligned}
                              u_2^W & =\beta_I,       \\
                              u_3^W & =\beta_{I+1},   \\
                                    & \vdotswithin{=} \\
                              u_J^W & =\beta_{I+J-2}.
                        \end{aligned}
                  \end{array} \]
      \item Testing independence in a 2-way table:
            \[ \HN\colon \pi_{ij}=\pi_{i\bullet}\pi_{\bullet j}\;\forall i,j \]
            \[ \HA\colon \pi_{ij}\ne \pi_{i\bullet}\pi_{\bullet j}\;\text{for some } i,j. \]
      \item The corresponding log-linear models are:
            \[ \HN\colon \log{\mu_{ij}}=u+u_i^V+u_j^W \]
            \[ \HA\colon\log{\mu_{ij}}=u+u_i^V+u_j^W+u_{ij}^{VW}. \]
      \item Using \textcolor{Blue}{corner-point constraints} we require:
            \[ u_1^V=0,\qquad u_1^W=0,\qquad u_{1j}^{VW}=0\;\forall j,\qquad u_{i1}^{VW}\;\forall i. \]
      \item The interaction model has $ 1+(I-1)+(J-1)+(I-1)(J-1)=IJ $ parameters.
      \item \textcolor{Red}{Wait}: We're using a \textcolor{Blue}{Poisson} model to fit data/test hypotheses from a \textcolor{Blue}{Multinomial} distribution?
      \item Examine the log-likelihood from the Poisson:
            \[ \ell(\Vector{\mu})=\sum_i\sum_j\bigl[y_{ij}\log{\mu_{ij}}-\mu_{ij}-\log{y_{ij}!}\bigr]. \]
      \item Substitute in the log linear model \textcolor{Blue}{$ \HN\colon \log{\mu_{ij}}=u+u_i^V+u_j^W $}:
            \begin{align*}
                  \ell(\Vector{u})
                                & =\sum\sum\bigl(y_{ij}(\textcolor{Blue}{u+u_i^V+u_j^W})-\exp{\textcolor{Blue}{u+u_i^V+u_j^W}}-\log{y_{ij}!}\bigr)          \\
                  \pdv{\ell}{u} & =\sum\sum\bigl(y_{ij}-\exp{u+u_i^V+u_j^W}\bigr)                                                                           \\
                                & =\sum\sum(y_{ij}-\mu_{ij})                                                                                                \\
                                & =y_{\bullet\bullet}-\mu_{\bullet\bullet}\qquad \text{(set $=0$)}\implies \hat{\mu}_{\bullet\bullet}=y_{\bullet\bullet}.   \\
                  \pdv{\ell}{u_{i^\star}^V}
                                & =\sum\sum\bigl(y_{i^\star j}-\exp{u+u_{i^\star}^V+u_j^W}\bigr)                                                            \\
                                & =y_{i^\star\bullet}-\mu_{i^\star\bullet}\qquad \text{(set $=0$)}\implies\hat{\mu}_{i\bullet}=y_{i\bullet}\;\forall i.     \\
                  \pdv{\ell}{u_{j^\star}^W}
                                & =\sum\sum\bigl(y_{ij^\star}-\exp{u+u_{i}^V+u_{j^\star}^W}\bigr)                                                           \\
                                & =y_{\bullet j^\star}-\mu_{\bullet j^\star}\qquad \text{(set $=0$)}\implies\hat{\mu}_{\bullet j}=y_{\bullet j}\;\forall j.
            \end{align*}
      \item So the main effects log linear model reproduces the row, column and grand totals.
      \item If we do the same with the saturated model
            \[ \HA\colon\log{\mu_{ij}}=u+u_i^V+u_j^W+u_{ij}^{VW}, \]
            we find it provides a perfect fit to the data: $ \tilde{\mu}_{ij}=y_{ij} $ for all $ i,j $.
      \item Recall the Deviance Test for the Poisson Distribution
            \begin{align*}
                  D
                   & =2\bigl(\ell(\tilde{\Vector{\mu}})-\ell(\hat{\Vector{\mu}})\bigr)                                                                                                   \\
                   & =2\sum\sum\Bigl(\bigl(y_{ij}-\log{\tilde{\mu}_{ij}}-\tilde{\mu}_{ij}-\log{y_{ij}!}\bigr)-\bigl(y_{ij}-\log{\hat{\mu}_{ij}}-\hat{\mu}_{ij}-\log{y_{ij}!}\bigr)\Bigr) \\
                   & =2\sum\sum\biggl(y_{ij}\log*{\frac{\tilde{\mu}_{ij}}{\hat{\mu}_{ij}}}-(\tilde{\mu}_{ij}-\hat{\mu}_{ij})\biggr)                                                      \\
                   & =2\sum\sum y_{ij}\log*{\frac{y_{ij}}{y_{i\bullet}y_{\bullet j}/y_{\bullet\bullet}}},
            \end{align*}
            since
            \begin{align*}
                  \hat{\mu}_{ij}
                   & =y_{\bullet\bullet}\hat{\pi}_{i\bullet}\hat{\pi}_{\bullet j}                                                                                                   \\
                   & =y_{\bullet\bullet}\biggl(\frac{\hat{\mu}_{i\bullet}}{\hat{\mu}_{\bullet\bullet}}\biggr)\biggl(\frac{\hat{\mu}_{\bullet j}}{\hat{\mu}_{\bullet\bullet}}\biggr) \\
                   & =y_{i\bullet}y_{\bullet j}/y_{\bullet\bullet},
            \end{align*}
            and
            \begin{align*}
                  \sum\sum\tilde{\mu}_{ij} & =\sum\sum u_{ij}=y_{\bullet\bullet},            \\
                  \sum\sum\hat{\mu}_{ij}   & =\hat{\mu}_{\bullet\bullet}=y_{\bullet\bullet}.
            \end{align*}
            \[ D=2\sum\sum y_{ij}\log*{\frac{y_{ij}}{y_{i\bullet}y_{\bullet j}/y_{\bullet\bullet}}}. \]
      \item We know $ D \sim \chi^2_{n-p} $ under $ \HN $. Here,
            \[ n-p=(I-J)-\bigl(1+(I-1)+(J-1)\bigr)=(I-1)(J-1). \]
      \item Same as the Likelihood Ratio/Deviance Test statistic from the \textcolor{Blue}{Multinomial} and
            \textcolor{Blue}{Product Multinomial} last section.
      \item Use the Deviance Test from fitting \textcolor{Blue}{Poisson} models to conduct hypotheses tests
            for data from 2-way contingency tables!
\end{itemize}
\subsection*{Example: A Melanoma Study}
\addcontentsline{toc}{subsection}{Example: A Melanoma Study}
\begin{itemize}
      \item A cross-sectional study was conducted in which 400 patients with malignant
            melanoma were classified according to two factors: the \textcolor{Blue}{site of the tumour} and the
            \textcolor{Blue}{histological type}.
            \begin{Example}{Melanoma Study Data}
                  \begin{center}
                        \begin{tabular}{lcccc}
                              Tumour Type           & Head and Neck & Trunk & Extremities & Total \\
                              \midrule
                              Hutchinson's freckle  & 22            & 2     & 10          & 34    \\
                              Superficial Spreading & 16            & 54    & 115         & 185   \\
                              Nodular               & 19            & 33    & 73          & 125   \\
                              Indeterminate         & 11            & 17    & 28          & 56    \\
                              Total                 & 68            & 106   & 226         & 400
                        \end{tabular}
                  \end{center}
            \end{Example}
      \item Here we wish to investigate whether the different types of tumour appear equally
            likely in the different sites.
      \item That is, we are assessing \textcolor{Green}{whether there is an association between
                  histological type and tumour site}.
      \item We wish to test for \textcolor{Blue}{independence}:
            \[ \HN\colon \pi_{ij}=\pi_{i\bullet}\pi_{\bullet j}\;\forall i,j \]
            \[ \HA\colon \pi_{ij}\ne \pi_{i\bullet}\pi_{\bullet j}\;\text{for some } i,j. \]
      \item Under $ \HN $: $ \mu_{ij}=\E{Y_{ij}}=y_{\bullet\bullet}\pi_{i\bullet}\pi_{\bullet j} $, meaning we will have to fit the row and
            column totals to allow estimation of $ \pi_{i\bullet} $ and $ \pi_{\bullet j} $.
      \item Thus, our log linear model under the null hypothesis is
            \[ \log{\mu_{ij}}=u+u_i^V+u_j^W,\; i=1,2,3,4,\,j=1,2,3 \]
      \item $V$ corresponds to tumour type variable ($i$ indicating the level).
      \item $W$ corresponds to tumour site variable ($j$ indicating the level).
      \item \textcolor{Blue}{If the model fits the data well, then there's no evidence against the assumption
                  that tumour type and site are independent}.
      \item If the model does not fit the data well, then some tumour types appear more
            frequently in certain locations.
\end{itemize}
\subsubsection*{R Dataset}
\begin{Example}{Melanoma Data Set}
      % \begin{noindent}
    <<echo=FALSE>>=
    derm.dat = read.table("derm.dat", header = T)
    derm.dat
    @
% \end{noindent}
\end{Example}
\subsubsection*{R Code}
%\begin{noindent}
    <<results='hide',fig.show='hide'>>=
    derm.dat = read.table("derm.dat", header = T)

    derm.dat$typef=factor(derm.dat$type)
    derm.dat$sitef=factor(derm.dat$locat)
    derm.dat

    # fitting the model with both main effects
    model1 = glm(y~typef+sitef,family=poisson,data=derm.dat)
    summary(model1)

    # creating deviance residuals for diagnostic plots
    derm.dat$fitted.values=model1$fitted.values
    derm.dat$rdeviance=residuals.glm(model1,type="deviance")
    derm.dat

    # fitting the model with only the "histological type" main effect
    model2 = glm(y~typef,family=poisson,data=derm.dat)
    1-pchisq(model2$deviance-model1$deviance,model2$df.residual-model1$df.residual)

    # fitting the model with only the "site" main effect
    model3 = glm(y~sitef,family=poisson,data=derm.dat)
    1-pchisq(model3$deviance-model1$deviance,model3$df.residual-model1$df.residual)
    @
%\end{noindent}
\begin{itemize}
      \item One line per cell in the contingency table.
      \item $IJ = 12$ observations.
      \item \texttt{type} is tumour type (4 levels).
      \item \texttt{locat} is tumour location (3 levels).
      \item \texttt{y} is the count in the contingency table.
\end{itemize}
\subsubsection*{R output for Model 1: \texttt{type + site}}
%\begin{noindent}
    <<>>=
    model1 = glm(y~typef+sitef,family=poisson,data=derm.dat)
    summary(model1)
    @
%\end{noindent}
\begin{itemize}
      \item Recall we are testing for \textcolor{Blue}{independence}
            \[ \HN\colon \pi_{ij}=\pi_{i\bullet}\pi_{\bullet j}\;\forall i,j \]
            \[ \HA\colon \pi_{ij}\ne \pi_{i\bullet}\pi_{\bullet j}\;\text{for some } i,j. \]
      \item The Deviance test statistic $ \chi^2_{12-6} $ under $ \HN $.
      \item Here $ D=51.795 $ which corresponds to a $ p $-value of
            \[ p=\Prob*{\chi^2_{6}>51.795}<0.001. \]
            Therefore, we reject the null hypothesis of independence.
            %\begin{noindent}
        <<>>=
        1-pchisq(model1$deviance,model1$df.residual)
        @
    %\end{noindent}
      \item Examine the fitted values and residuals.
            %\begin{noindent}
        <<>>=
        derm.dat
        @
    %\end{noindent}
      \item Can verify that the row and column totals are fit exactly.
      \item For example, sum the first three observations corresponding to the total number of
            Hutchinson freckle cases, and sum the corresponding fitted values.
      \item We conclude that the model does not provide a very good fit to the data since
            there are some rather large deviance residuals corresponding to the first two rows
            of the table.
      \item Therefore, our hypothesis that tumour type and site are independent does not
            seem plausible.
      \item Specifically, based on the fitted values and residuals we see that Hutchinson's
            freckle occurs more often on the head and neck than we would expect under the
            independence assumption, and less often on the trunk and extremities.
      \item Furthermore, superficial spreading melanoma occurs less often on the head and
            neck than we would expect.
      \item Can we use a smaller model?
\end{itemize}
\subsubsection*{R output for Model 2: \texttt{type}}
%\begin{noindent}
    <<>>=
    model2 = glm(y~typef,family=poisson,data=derm.dat)
    summary(model2)
    @
%\end{noindent}
\begin{itemize}
      \item Model 2: $ \log{\mu_{ij}}=u+u_i^V $ for $ i=1,2,3,4 $ and $ j=1,2,3 $ with $ u_1^V=0 $.
      \item Now we are testing
            \[ \HN\colon \pi_{ij}=\pi_{i\bullet}/J\;\forall i, \]
            \[ \HA\colon \exists i\text{ such that }\pi_{ij}\ne \pi_{i\bullet}/J \]
      \item The Deviance test statistic $ \Delta D=D_0-D_A \sim \chi^2_{J-1} $ under $ \HN $.
      \item Here $ \Delta D=150.1-51.795 $ which corresponds to a $ p $-value of
            \[ p=\Prob*{\chi^2_{2}>98.305}<0.001 \]
            Therefore, we reject the null hypothesis that all location occur with equal frequency.
            %\begin{noindent}
        <<>>=
        1-pchisq(model2$deviance-model1$deviance,model2$df.residual-model1$df.residual)
        @
    %\end{noindent}
\end{itemize}
\subsubsection*{R output for Model 3: \texttt{site}}
%\begin{noindent}
    <<>>=
    model3 = glm(y~sitef,family=poisson,data=derm.dat)
    summary(model3)
    1-pchisq(model3$deviance-model1$deviance,model3$df.residual-model1$df.residual)
    @
%\end{noindent}
\begin{itemize}
      \item Therefore, we reject the null hypothesis that different tumour types occur equally often when controlled for sites.
\end{itemize}
\subsubsection*{Summary: A Melanoma Study}
\begin{itemize}
      \item Row Percentages:
            \begin{table}[H]
                  \centering
                  \begin{tabular}{lcccc}
                        Tumour Type           & Head and Neck & Trunk & Extremities & Total \\
                        \midrule
                        Hutchinson's freckle  & 64.7          & 5.9   & 29.4        & 100   \\
                        Superficial Spreading & 8.6           & 29.2  & 62.2        & 100   \\
                        Nodular               & 15.2          & 26.4  & 58.4        & 100   \\
                        Indeterminate         & 19.6          & 30.4  & 50.0        & 100   \\
                        Total                 & 17.0          & 26.5  & 56.5        & 100
                  \end{tabular}
            \end{table}
      \item Column Percentages:
            \begin{table}[H]
                  \centering
                  \begin{tabular}{lcccc}
                        Tumour Type           & Head and Neck & Trunk & Extremities & Total \\
                        \midrule
                        Hutchinson's freckle  & 32.4          & 1.9   & 4.4         & 8.5   \\
                        Superficial Spreading & 23.5          & 50.9  & 50.9        & 46.25 \\
                        Nodular               & 27.9          & 31.1  & 32.3        & 31.25 \\
                        Indeterminate         & 16.2          & 16.0  & 12.4        & 14.00 \\
                        Total                 & 100           & 100   & 100         & 100
                  \end{tabular}
            \end{table}
      \item We rejected the null hypothesis that tumour type and site are independent.
      \item In addition, further investigation indicates that the different tumour types do not
            occur equally often, and melanoma does not occur equally often at the different
            sites of the body.
      \item See Course Notes for example of fitting model 1 with ANOVA constraints
            ($ \sum_i u_i^V=0 $ and $ \sum_j u_j^W =0$) instead of corner-point constraints ($ u_1^V=u_1^W=0 $).
      \item Coefficient estimates and correlation matrix change.
      \item Deviance, deviance residuals, and fitted values are unchanged.
\end{itemize}
\subsection*{Revisit the example from last section}
\addcontentsline{toc}{subsection}{Example: Self-Examination Data}
\begin{Example}{Breast Self-Examination Contingency Table}
      \begin{center}
            \begin{NiceTabular}{c|ccc|c}[first-row,first-col]
                  &&\Block{1-3}{Frequency of breast self-examination}\\
                  && Monthly & Occasionally & Never & Total\\
                  \midrule
                  \Block{3-1}{Age} & $<$45 & $ 91 $ & $ 90 $ & $ 51 $ & $ 232 $\\
                  & 45--59 & $ 150 $ & $ 200 $ & $ 155 $ & $ 505 $\\
                  & $ \ge $60 & $ 109 $ & $ 198 $ & $ 172 $ & $ 479 $\\
                  \midrule
                  & Total & $ 350 $ & $ 488 $ & $ 378 $ & $ 1216 $
            \end{NiceTabular}
      \end{center}
\end{Example}
\begin{itemize}
      \item Last class we rejected the null hypothesis that Age and Frequency of breast
            self-examination are independent:
            \[ D=2\sum_i\sum_j y_{ij}\log*{\frac{y_{ij}}{y_{i\bullet}y_{\bullet j}/y_{\bullet\bullet}}}=25.19226. \]
            \[ p=\Prob*{\chi^2_{4}>25.19226}<0.001. \]
\end{itemize}
\subsubsection*{R Code}
%\begin{noindent}
    <<results='hide',fig.show='hide'>>=
    # Breast Self-Examination Contingency Table Analysis
    y=c(91,90,51,150,200,155,109,198,172)
    Age=as.factor(c(1,1,1,2,2,2,3,3,3))
    Freq=as.factor(c(1,2,3,1,2,3,1,2,3))
    Exam=data.frame(Age,Freq,y)

    # Fit main effects log linear model
    model1=glm(y~Age+Freq,family=poisson)
    summary(model1)
    1-pchisq(model1$deviance,model1$df.residual)

    # Examine fitted values and deviance residuals
    Exam$fv=model1$fitted.values
    Exam$rd=residuals.glm(model1,type="deviance")
    Exam
    @
%\end{noindent}
\subsubsection*{R Output for Main Effects Model}
%\begin{noindent}
    <<>>=
        # Fit main effects log linear model
        model1=glm(y~Age+Freq,family=poisson)
    summary(model1)
    1-pchisq(model1$deviance,model1$df.residual)
    Exam$fv=model1$fitted.values
    Exam$rd=residuals.glm(model1,type="deviance")
    Exam
    @
%\end{noindent}
\begin{itemize}
      \item Reject $ \HN $ that main effects model is adequate, that is, we reject $ \HN $
            that age and frequency are independent.
      \item Same Deviance Test statistic as what we calculated based on the multinomial
            distribution.
      \item Compare the above fitted values to the expected data under $ \HN $ (last lecture).
\end{itemize}