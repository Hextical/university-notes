\section{2020-03-25: Interval Estimation and Hypothesis for Beta}
\underline{Roadmap}:
\begin{enumerate}[(i)]
    \item Confidence Interval for $ \beta $
    \item Testing for $ H_0 $: $ \beta=0 $ (Test for correlation for
          $ x $ and $ Y $)
\end{enumerate}

\begin{exbox}
    \begin{example} \label{ex least sq}
        Last class we found the least square equation using the following data.
        \begin{itemize}
            \item $ n=30 $
            \item $ \overline{x}=76.733 $
            \item $ \overline{y}=72.233 $
            \item $ S_{yy}=7585.3667 $
            \item $ S_{xx}=5135.8667 $
            \item $ S_{xy}=5106.8667 $
            \item $ \hat{\alpha}=-4.0677 $
            \item $ \hat{\beta}=0.9944 $
        \end{itemize}
        \[ y=-4.0677+0.9944x \]
        \begin{itemize}
            \item $ \hat{\sigma}^2=\frac{1}{n} \sum\limits_{i=1}^{n} \left[ y_i-(\hat{\alpha}+\hat{\beta}x_i) \right]^2 $
        \end{itemize}
        We now introduce the standard error, denoted $ s_e $, where we divide by $ (n-2) $
        instead of $ (n-1) $ in our sample standard variance.
        \[ s_e^2=\frac{1}{n-2} \sum\limits_{i=1}^{n} \left[ y_i-(\hat{\alpha}+\hat{\beta}x_i) \right]^2 \]
        In our example, $ s_e=9.4630 $. Don't forget to square root $ s_e^2 $!

        A look ahead: $ s_e^2 $ is an unbiased estimator for $ \sigma^2 $.
    \end{example}
\end{exbox}
\underline{Some Algebra}
\[ \begin{aligned}
        S_{xy} & = & \sum\limits_{i=1}^{n} (x_i-\overline{x})(y_i-\overline{y}) & = & \sum\limits_{i=1}^{n} (x_i-\overline{x})y_i                \\
               & = & \sum\limits_{i=1}^{n} x_i(y_i-\overline{y})                & = & \sum\limits_{i=1}^{n} (x_iy_i) - n\overline{x}\overline{y}
    \end{aligned}
\]
\[ S_{xx}=\sum\limits_{i=1}^{n}(x_i-\overline{x})^2=\sum\limits_{i=1}^{n} (x_i-\overline{x})x_i \]
Thus,
\[ \hat{\beta}=\frac{S_{xy}}{S_{xx}}=\frac{\sum\limits_{i=1}^{n} (x_i-\overline{x})y_i}{S_{xx}}=\sum\limits_{i=1}^{n} a_iy_i  \]
where $ a_i=\frac{x_i-\overline{x}}{S_{xx}} $.
Also,
\[ \tilde{\beta}=\sum\limits_{i=1}^{n} a_iY_i \]
Result:
\[ \tilde{\beta} \thicksim N\left(\beta,\frac{\sigma^2}{S_{xx}}\right) \]
Therefore,
\[ \frac{\tilde{\beta}-\beta}{\frac{\sigma}{\sqrt{S_{xx}}}} \thicksim N(0,1) \]
but, $ \sigma $ is unknown, so
\[ \frac{\tilde{\beta}-\beta}{\frac{S_e}{\sqrt{S_{xx}}}} \thicksim T_{n-2}  \]
\begin{thmbox}
    \begin{theorem} We can use
        \[ \frac{\tilde{\beta}-\beta}{\frac{S_e}{\sqrt{S_{xx}}}} \thicksim T_{n-2} \]
        as a pivotal quantity for $ \beta $. We can use
        \[ \frac{(n-2)S_e^2}{\sigma^2} \thicksim \chi^2_{n-2} \]
        as a pivotal quantity for $ \sigma^2 $.
    \end{theorem}
\end{thmbox}
\begin{exbox}
    \begin{example} Continuation of \ref{ex least sq}.
        \begin{enumerate}[(i)]
            \item Find the $ 95\% $ Confidence Interval for $ \beta $.
            \item Test whether $ \beta=0 $
        \end{enumerate}
        (i) The pivot is:
        \[ \frac{\tilde{\beta}-\beta}{\frac{S_e}{\sqrt{S_{xx}}}} \thicksim T_{28} \]
        \underline{Step 1}: Critical points using table with $ p=0.975,\,df=28\rightarrow t^*=2.05 $.
        \[ P\left(-2.05\leqslant \frac{\tilde{\beta}-\beta}{\frac{S_e}{\sqrt{S_{xx}}}}\leqslant 2.05\right)=0.95\]
        Coverage interval:
        \[ \tilde{\beta}\pm t^* \frac{S_e}{\sqrt{S_{xx}}} \]
        Confidence interval:
        \[ \tilde{\beta}\pm t^* \frac{s_e}{\sqrt{s_{xx}}} \]
        \[ \implies [0.72,1.26] \]
        (ii) We know $ \beta=[0.72,1.26] $. We want to test $ \beta=0 $ (we can already see it's
        not within this interval).
        \begin{itemize}
            \item $ H_0 $: $ \beta=0 $
            \item $ H_1 $: $ \beta\neq 0 $
        \end{itemize}
        \[ D=\left|\frac{\tilde{\beta}}{\frac{S_e}{\sqrt{S_{xx}}}}\right| \]
        Value of the test:
        \[ d=\frac{\hat{\beta}}{\frac{s_e}{s_{xx}}}=\frac{0.9944}{\frac{9.4630}{\sqrt{5135.8667}}}=7.53 \]
        \begin{align*}
            p\text{-value}
             & =P(D\geqslant d)           \\
             & =P(|T_{28}|\geqslant 7.53) \\
             & \approx 0
        \end{align*}
        There is very strong evidence against $ H_0 $.
        We could also test for any $ \beta=\beta_0\in\mathbb{R} $.
    \end{example}
\end{exbox}
