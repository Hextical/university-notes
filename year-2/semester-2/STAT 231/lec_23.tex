\section{2020-03-04}

\begin{Definition}{}{}
    An estimator $ \tilde{\theta} $ is called \textbf{\emph{unbiased}} for $ \theta $ if
    \[ E(\tilde{\theta})=\theta \]
\end{Definition}


\begin{Example}{}{}
    Let $ W=\frac{(n-1)S^2}{\sigma^2} $. Prove $ S^2 $ is an unbiased
    estimator for $ \sigma^2 $.

    \textbf{Solution.}
    \begin{align*}
         & E(W)=n-1                                              \\
         & \implies E\left(\frac{(n-1)S^2}{\sigma^2} \right)=n-1 \\
         & \implies \frac{n-1}{\sigma^2} E(S^2)=n-1              \\
         & \implies E(S^2)=\sigma^2
    \end{align*}
    Thus, $ S^2 $ is an unbiased estimator for $ \sigma^2 $ by definition.
\end{Example}


\underline{Other Confidence Intervals}

\underline{Poisson}
Suppose $ Y_1,\ldots ,Y_n \sim \poi{\mu} $
are independent and $ n $ is large. Find the $ 95\% $ confidence interval.
\[ \overline{Y} \sim N(\mu,\sigma^2=\sfrac{\mu}{n}) \]
Find the pivotal quantity now.

\underline{Exponential}
Suppose $ Y_1,\ldots ,Y_n \sim \exponential{\theta} $ are independent and $ n $ is small.


\begin{Theorem}{}{}
    If $ Y \sim \exponential{\theta} $, then
    \[ \frac{2Y}{\theta} \sim \exponential{2} \]
    If $ W_i=\sfrac{2Y_i}{\theta} $, then
    \[ \sum\limits_{i=1}^{n} W_i \sim \chi^2_{2n} \]
\end{Theorem}

\begin{Proof}{}{}
    Let $ F_W(w) $ be the cumulative distribution function of $ W $. Then,
    \begin{align*}
        F_W(w)
         & =P(W\leqslant w)                               \\
         & =P\left( \frac{2Y}{\theta} \leqslant w \right) \\
         & =P\left( Y\leqslant \frac{w\theta}{2} \right)  \\
         & =1-e^{-\frac{w\theta/2}{\theta}}               \\
         & =1-e^{-\sfrac{w}{2}}
    \end{align*}
    Therefore,
    \[ f(w)=\frac{1}{2} e^{-\sfrac{w}{2}} \]
\end{Proof}
Using this theorem, we can find the confidence interval for $ \theta $.
\begin{align*}
     & P\left(a\leqslant \chi^2_{2n}\leqslant b\right)=0.95                                         \\
     & \implies P\left(a \leqslant \sum\limits_{i=1}^{n} W_i \leqslant b\right)=0.95                \\
     & \implies P\left(a\leqslant \sum\limits_{i=1}^{n} \frac{2Y_i}{\theta} \leqslant b\right)=0.95 \\
     & \implies P\left(a\leqslant \frac{2}{\theta} \sum\limits_{i=1}^{n} Y_i\leqslant b\right)=0.95
\end{align*}
yields
\[ \left[ \frac{2 \sum\limits_{i=1}^{n} Y_i}{b} , \frac{2 \sum\limits_{i=1}^{n} Y_i}{a} \right] \]
where $ a $ and $ b $ are from the $ \chi^2 $ table.


\begin{Theorem}{}{}
    If we have a $ p\% $ coverage interval with $ Z $ as a pivot, and $ n $ is large, then
    the corresponding likelihood is given by
    \[ \exp\left[-\sfrac{(z^*)^2}{2}\right] \]
\end{Theorem}



\begin{Example}{}{}
    If $ p=0.95 $ and $ z^*=1.96 $, then the corresponding likelihood is:
    \[ \exp\left[-\sfrac{(1.96)^2}{2}\right] \approx 0.15 \]
\end{Example}

